{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ego-rnn-RGB_LDN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNYyOE7Mqm3FPDTHHYTBBPc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2OU3pQgxiN8n","colab_type":"code","outputId":"188c1681-18e3-4e33-ed34-29a922e97b03","executionInfo":{"status":"ok","timestamp":1591170725902,"user_tz":-120,"elapsed":21687,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNEChItX68qN","colab_type":"code","colab":{}},"source":["#%cp \"-r\" \"/content/drive/My Drive/Lorenzo/ego-rnn-latest/genAttentionMap.py\" \"/content/drive/My Drive/Lorenzo/ego-rnn-ss-task/\" "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUJ6IA36Y9Pp","colab_type":"code","outputId":"8bb08def-8762-4803-cd14-665cb5661113","executionInfo":{"status":"ok","timestamp":1591170993692,"user_tz":-120,"elapsed":108781,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"source":["%cd \"/content/\"\n","!wget -O \"frames.tar.xz\" \"https://mybucketmldl.s3.amazonaws.com/processed_frames.tar.xz\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","--2020-06-03 07:54:46--  https://mybucketmldl.s3.amazonaws.com/processed_frames.tar.xz\n","Resolving mybucketmldl.s3.amazonaws.com (mybucketmldl.s3.amazonaws.com)... 52.216.229.171\n","Connecting to mybucketmldl.s3.amazonaws.com (mybucketmldl.s3.amazonaws.com)|52.216.229.171|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3579197744 (3.3G) [application/x-xz]\n","Saving to: ‘frames.tar.xz’\n","\n","frames.tar.xz       100%[===================>]   3.33G  32.8MB/s    in 1m 45s  \n","\n","2020-06-03 07:56:32 (32.4 MB/s) - ‘frames.tar.xz’ saved [3579197744/3579197744]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jozu0Z_Rsbt7","colab_type":"code","colab":{}},"source":["!tar \"xf\" \"frames.tar.xz\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oBoVC4ZQia5z","colab_type":"code","outputId":"1d399335-3054-457b-b54b-e7529cac1932","executionInfo":{"status":"ok","timestamp":1591181820656,"user_tz":-120,"elapsed":949,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd \"/content/drive/My Drive/Lorenzo/ego-rnn-latest\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Lorenzo/ego-rnn-latest\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"389pw3Ang7sD","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","from objectAttentionModelConvLSTM import *\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n","                                RandomHorizontalFlip)\n","from makeDatasetFrame import *\n","import argparse\n","import sys\n","\n","DEVICE = \"cuda\"\n","VAL_FREQUENCY = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnxYxClIg0eE","colab_type":"code","colab":{}},"source":["def main_run(version, stage, train_data_dir, stage1_dict, out_dir, seqLen, trainBatchSize,\n","             valBatchSize, numEpochs, lr1, decay_factor, decay_step, mem_size):\n","    num_classes = 61\n","\n","    model_folder = os.path.join(\"./\", out_dir, version)\n","\n","    if os.path.exists(model_folder):\n","        print('Directory {} exists!'.format(model_folder))\n","        sys.exit()\n","    os.makedirs(model_folder)\n","\n","    train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","    train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","    val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","    val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')\n","\n","    # Train val partitioning\n","    train_usr = [\"S1\", \"S3\", \"S4\"]\n","    val_usr = [\"S2\"]\n","\n","    # Data loader\n","    normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    spatial_transform = Compose(\n","        [Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n","         ToTensor(), normalize])\n","\n","    vid_seq_train = makeDataset(train_data_dir, train_usr,\n","                                spatial_transform=spatial_transform, seqLen=seqLen)\n","\n","    train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n","                                               shuffle=True, num_workers=4, pin_memory=True)\n","\n","    vid_seq_val = makeDataset(train_data_dir, val_usr,\n","                              spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n","                              seqLen=seqLen)\n","\n","    val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n","                                             shuffle=False, num_workers=2, pin_memory=True, phase=\"test\")\n","\n","    train_params = []\n","\n","    # stage 1: train only lstm\n","    if stage == 1:\n","\n","        model = attentionModel(num_classes=num_classes, mem_size=mem_size)\n","        model.train(False)\n","        for params in model.parameters():\n","            params.requires_grad = False\n","\n","    # stage 2: train lstm, layer4, spatial attention and final fc\n","    else:\n","        model = attentionModel(num_classes=num_classes, mem_size=mem_size)\n","        model.load_state_dict(torch.load(stage1_dict))  # pretrained\n","        model.train(False)\n","        for params in model.parameters():\n","            params.requires_grad = False\n","        #\n","        for params in model.resNet.layer4[0].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[0].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[1].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[1].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[2].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","        #\n","        for params in model.resNet.layer4[2].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","        #\n","        for params in model.resNet.fc.parameters():  # fully connected layer\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        model.resNet.layer4[0].conv1.train(True)\n","        model.resNet.layer4[0].conv2.train(True)\n","        model.resNet.layer4[1].conv1.train(True)\n","        model.resNet.layer4[1].conv2.train(True)\n","        model.resNet.layer4[2].conv1.train(True)\n","        model.resNet.layer4[2].conv2.train(True)\n","        model.resNet.fc.train(True)\n","\n","    for params in model.lstm_cell.parameters():  # for both stages we train the lstm\n","        params.requires_grad = True\n","        train_params += [params]\n","\n","    for params in model.classifier.parameters():  # for both stages we train the last classifier (after the lstm and avg pooling)\n","        params.requires_grad = True\n","        train_params += [params]\n","\n","    model.lstm_cell.train(True)\n","\n","    model.classifier.train(True)\n","    model.cuda()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n","\n","    optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                           gamma=decay_factor)\n","\n","    train_iter = 0\n","    min_accuracy = 0\n","\n","    for epoch in range(numEpochs):\n","        optim_scheduler.step()\n","        epoch_loss = 0\n","        numCorrTrain = 0\n","        trainSamples = 0\n","        iterPerEpoch = 0\n","        model.lstm_cell.train(True)\n","        model.classifier.train(True)\n","        if stage == 2:\n","            model.resNet.layer4[0].conv1.train(True)\n","            model.resNet.layer4[0].conv2.train(True)\n","            model.resNet.layer4[1].conv1.train(True)\n","            model.resNet.layer4[1].conv2.train(True)\n","            model.resNet.layer4[2].conv1.train(True)\n","            model.resNet.layer4[2].conv2.train(True)\n","            model.resNet.fc.train(True)\n","        for i, (inputs, inputsF, targets) in enumerate(train_loader):\n","            train_iter += 1\n","            iterPerEpoch += 1\n","            optimizer_fn.zero_grad()\n","            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).to(DEVICE))\n","            labelVariable = Variable(targets.to(DEVICE))\n","            trainSamples += inputs.size(0)\n","            output_label, _ = model(inputVariable)\n","            loss = loss_fn(output_label, labelVariable)\n","            loss.backward()\n","            optimizer_fn.step()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorrTrain += (predicted == targets.to(DEVICE)).sum()  # evaluating number of correct classifications\n","            epoch_loss += loss.data.item()\n","        avg_loss = epoch_loss / iterPerEpoch\n","        trainAccuracy = (numCorrTrain.data.item() / trainSamples)\n","\n","        train_log_loss.write('Training loss after {} epoch = {}\\n'.format(epoch + 1, avg_loss))  # log file\n","        train_log_acc.write('Training accuracy after {} epoch = {}\\n'.format(epoch + 1, trainAccuracy))  # log file\n","        print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch + 1, avg_loss, trainAccuracy))\n","\n","        if (epoch + 1) % VAL_FREQUENCY == 0:\n","            model.train(False)\n","            val_loss_epoch = 0\n","            val_iter = 0\n","            val_samples = 0\n","            numCorr = 0\n","            for j, (inputs, inputsF, targets) in enumerate(val_loader):\n","                val_iter += 1\n","                val_samples += inputs.size(0)\n","                inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).to(DEVICE))\n","                labelVariable = Variable(targets.to(DEVICE))\n","                output_label, _ = model(inputVariable)\n","                val_loss = loss_fn(output_label, labelVariable)\n","                val_loss_epoch += val_loss.data.item()\n","                _, predicted = torch.max(output_label.data, 1)\n","                numCorr += (predicted == targets.to(DEVICE)).sum()  # evaluating number of correct classifications\n","            val_accuracy = (numCorr.data.item() / val_samples)\n","            avg_val_loss = val_loss_epoch / val_iter\n","            print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","            val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))  # log file\n","            val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))  # log file\n","            if val_accuracy > min_accuracy:\n","                save_path_model = (\n","                        model_folder + '/model_rgb_state_dict.pth')  # every epoch, check if the val accuracy is improved, if so, save that model\n","                torch.save(model.state_dict(),\n","                           save_path_model)  # in that way, even if the model overfit, you will get always the best model\n","                min_accuracy = val_accuracy  # in this way you don't have to care too much about the number of epochs\n","\n","    train_log_loss.close()\n","    train_log_acc.close()\n","    val_log_acc.close()\n","    val_log_loss.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRd39-S8g4Yz","colab_type":"code","colab":{}},"source":["def __main__():\n","    version = \"rgb_16frames_noCAM\"\n","    trainDatasetDir = \"/content/\"\n","    outDir = \"results\"onli\n","    stage1Dict = \"./\" + outDir + \"/\" + version + \"_1/model_rgb_state_dict.pth\"  # args.stage1Dict\n","\n","    # STAGE 1 PARAMETERS\n","    ST1_seqLen = 16  # 7\n","    ST1_trainBatchSize = 32  # 32\n","    ST1_valBatchSize = 32  # 32\n","    ST1_numEpochs = 200  # 200\n","    ST1_lr1 = 1e-3  # 1e-3\n","    ST1_stepSize = [25, 75, 150]  # [25, 75, 150]\n","    ST1_decayRate = 0.1  # 0.1\n","    ST1_memSize = 512  # 512\n","\n","    # STAGE 2 PARAMETERS\n","    ST2_seqLen = 16  # 7\n","    ST2_trainBatchSize = 32  # 32\n","    ST2_valBatchSize = 32  # 32\n","    ST2_numEpochs = 150  # 150\n","    ST2_lr1 = 1e-4  # 1e-4\n","    ST2_stepSize = [25, 75]  # [25, 75]\n","    ST2_decayRate = 0.1  # 0.1\n","    ST2_memSize = 512  # 512\n","\n","    # STAGE 1\n","    \n","    main_run(version + \"_1\",\n","             stage=1,\n","             train_data_dir=trainDatasetDir,\n","             stage1_dict=stage1Dict,\n","             out_dir=outDir,\n","             seqLen=ST1_seqLen,\n","             trainBatchSize=ST1_trainBatchSize,\n","             valBatchSize=ST1_valBatchSize,\n","             numEpochs=ST1_numEpochs,\n","             lr1=ST1_lr1,\n","             decay_factor=ST1_decayRate,\n","             decay_step=ST1_stepSize,\n","             mem_size=ST1_memSize)\n","    \n","    # STAGE 2\n","    main_run(version + \"_2\",\n","             stage=2,\n","             train_data_dir=trainDatasetDir,\n","             stage1_dict=stage1Dict,\n","             out_dir=outDir,\n","             seqLen=ST2_seqLen,\n","             trainBatchSize=ST2_trainBatchSize,\n","             valBatchSize=ST2_valBatchSize,\n","             numEpochs=ST2_numEpochs,\n","             lr1=ST2_lr1,\n","             decay_factor=ST2_decayRate,\n","             decay_step=ST2_stepSize,\n","             mem_size=ST2_memSize)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4eZN7d5i2qy","colab_type":"code","colab":{}},"source":["#!rm \"-r\" \"./results\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ymmr3V-Eg_fo","colab_type":"code","outputId":"f59f389e-89ac-4715-82bf-d7dbf7b3d976","executionInfo":{"status":"ok","timestamp":1591198882228,"user_tz":-120,"elapsed":111447,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["__main__()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["skipped /content/processed_frames/S1/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S1/take_honey/3, different frame number\n","skipped /content/processed_frames/S1/take_peanut/1, different frame number\n","skipped /content/processed_frames/S3/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S3/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/4, different frame number\n","skipped /content/processed_frames/S3/stir_spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/4, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S2/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S2/take_mustard/1, different frame number\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:31: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_i_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:32: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_i_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:33: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_i_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:35: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_f_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:36: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_f_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:37: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_f_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:39: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_c_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_c_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:41: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_c_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:43: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_o_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:44: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_o_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-latest/MyConvLSTMCell.py:45: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_o_hh.weight)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Train: Epoch = 1 | Loss = 8.471010598269375 | Accuracy = 0.012307692307692308\n","Train: Epoch = 2 | Loss = 4.829988046125933 | Accuracy = 0.033846153846153845\n","Train: Epoch = 3 | Loss = 4.095262159000743 | Accuracy = 0.046153846153846156\n","Train: Epoch = 4 | Loss = 4.08017221364108 | Accuracy = 0.046153846153846156\n","Train: Epoch = 5 | Loss = 4.00808082927357 | Accuracy = 0.06153846153846154\n","Val: Epoch = 5 | Loss 3.9054479002952576 | Accuracy = 0.043859649122807015\n","Train: Epoch = 6 | Loss = 3.978919180956754 | Accuracy = 0.06461538461538462\n","Train: Epoch = 7 | Loss = 3.9511786590922964 | Accuracy = 0.08615384615384615\n","Train: Epoch = 8 | Loss = 3.934483203020963 | Accuracy = 0.08\n","Train: Epoch = 9 | Loss = 3.897888270291415 | Accuracy = 0.08\n","Train: Epoch = 10 | Loss = 3.8974863182414663 | Accuracy = 0.055384615384615386\n","Val: Epoch = 10 | Loss 3.7951558232307434 | Accuracy = 0.08771929824561403\n","Train: Epoch = 11 | Loss = 3.8695308945395728 | Accuracy = 0.052307692307692305\n","Train: Epoch = 12 | Loss = 3.8738617463545366 | Accuracy = 0.07384615384615385\n","Train: Epoch = 13 | Loss = 3.8716444318944756 | Accuracy = 0.07384615384615385\n","Train: Epoch = 14 | Loss = 3.8899989995089443 | Accuracy = 0.06153846153846154\n","Train: Epoch = 15 | Loss = 3.8459752906452525 | Accuracy = 0.07692307692307693\n","Val: Epoch = 15 | Loss 3.6542399525642395 | Accuracy = 0.13157894736842105\n","Train: Epoch = 16 | Loss = 3.776310617273504 | Accuracy = 0.08\n","Train: Epoch = 17 | Loss = 3.7575986818833784 | Accuracy = 0.08923076923076922\n","Train: Epoch = 18 | Loss = 3.74628192728216 | Accuracy = 0.08\n","Train: Epoch = 19 | Loss = 3.741332162510265 | Accuracy = 0.11692307692307692\n","Train: Epoch = 20 | Loss = 3.7061433575370093 | Accuracy = 0.10461538461538461\n","Val: Epoch = 20 | Loss 3.6044859290122986 | Accuracy = 0.13157894736842105\n","Train: Epoch = 21 | Loss = 3.6352281136946245 | Accuracy = 0.08923076923076922\n","Train: Epoch = 22 | Loss = 3.718498945236206 | Accuracy = 0.10461538461538461\n","Train: Epoch = 23 | Loss = 3.661216822537509 | Accuracy = 0.10153846153846154\n","Train: Epoch = 24 | Loss = 3.552798487923362 | Accuracy = 0.09846153846153846\n","Train: Epoch = 25 | Loss = 3.563914732499556 | Accuracy = 0.14461538461538462\n","Val: Epoch = 25 | Loss 3.459340214729309 | Accuracy = 0.15789473684210525\n","Train: Epoch = 26 | Loss = 3.5009297024119985 | Accuracy = 0.1476923076923077\n","Train: Epoch = 27 | Loss = 3.571601564233953 | Accuracy = 0.11692307692307692\n","Train: Epoch = 28 | Loss = 3.4697303771972656 | Accuracy = 0.11692307692307692\n","Train: Epoch = 29 | Loss = 3.5382422533902256 | Accuracy = 0.11384615384615385\n","Train: Epoch = 30 | Loss = 3.434566996314309 | Accuracy = 0.15076923076923077\n","Val: Epoch = 30 | Loss 3.4197152256965637 | Accuracy = 0.16666666666666666\n","Train: Epoch = 31 | Loss = 3.5230022343722256 | Accuracy = 0.11692307692307692\n","Train: Epoch = 32 | Loss = 3.549995530735363 | Accuracy = 0.10153846153846154\n","Train: Epoch = 33 | Loss = 3.433548840609464 | Accuracy = 0.13230769230769232\n","Train: Epoch = 34 | Loss = 3.4494373581626196 | Accuracy = 0.16307692307692306\n","Train: Epoch = 35 | Loss = 3.549239917234941 | Accuracy = 0.13538461538461538\n","Val: Epoch = 35 | Loss 3.391364872455597 | Accuracy = 0.15789473684210525\n","Train: Epoch = 36 | Loss = 3.503268978812478 | Accuracy = 0.11384615384615385\n","Train: Epoch = 37 | Loss = 3.447484341534701 | Accuracy = 0.14461538461538462\n","Train: Epoch = 38 | Loss = 3.4606342098929663 | Accuracy = 0.13846153846153847\n","Train: Epoch = 39 | Loss = 3.3638302846388384 | Accuracy = 0.15076923076923077\n","Train: Epoch = 40 | Loss = 3.3937308354811235 | Accuracy = 0.14153846153846153\n","Val: Epoch = 40 | Loss 3.32734614610672 | Accuracy = 0.14912280701754385\n","Train: Epoch = 41 | Loss = 3.487071839245883 | Accuracy = 0.1476923076923077\n","Train: Epoch = 42 | Loss = 3.4744796969673852 | Accuracy = 0.13846153846153847\n","Train: Epoch = 43 | Loss = 3.4748231280933726 | Accuracy = 0.11384615384615385\n","Train: Epoch = 44 | Loss = 3.3307965885509145 | Accuracy = 0.16615384615384615\n","Train: Epoch = 45 | Loss = 3.2991452433846216 | Accuracy = 0.1723076923076923\n","Val: Epoch = 45 | Loss 3.2864128947257996 | Accuracy = 0.14035087719298245\n","Train: Epoch = 46 | Loss = 3.366235451264815 | Accuracy = 0.13846153846153847\n","Train: Epoch = 47 | Loss = 3.391073790463534 | Accuracy = 0.13846153846153847\n","Train: Epoch = 48 | Loss = 3.4015003551136362 | Accuracy = 0.1476923076923077\n","Train: Epoch = 49 | Loss = 3.3597481467507104 | Accuracy = 0.14461538461538462\n","Train: Epoch = 50 | Loss = 3.391471407630227 | Accuracy = 0.15384615384615385\n","Val: Epoch = 50 | Loss 3.2668965458869934 | Accuracy = 0.16666666666666666\n","Train: Epoch = 51 | Loss = 3.358658335425637 | Accuracy = 0.1476923076923077\n","Train: Epoch = 52 | Loss = 3.339489394968206 | Accuracy = 0.16923076923076924\n","Train: Epoch = 53 | Loss = 3.4209721955386074 | Accuracy = 0.11692307692307692\n","Train: Epoch = 54 | Loss = 3.318439093503085 | Accuracy = 0.17846153846153845\n","Train: Epoch = 55 | Loss = 3.250894784927368 | Accuracy = 0.16615384615384615\n","Val: Epoch = 55 | Loss 3.2015642523765564 | Accuracy = 0.14912280701754385\n","Train: Epoch = 56 | Loss = 3.224218650297685 | Accuracy = 0.16307692307692306\n","Train: Epoch = 57 | Loss = 3.311199903488159 | Accuracy = 0.16923076923076924\n","Train: Epoch = 58 | Loss = 3.2056950222362173 | Accuracy = 0.19692307692307692\n","Train: Epoch = 59 | Loss = 3.2628086263483222 | Accuracy = 0.18769230769230769\n","Train: Epoch = 60 | Loss = 3.3024013475938276 | Accuracy = 0.17846153846153845\n","Val: Epoch = 60 | Loss 3.182657778263092 | Accuracy = 0.18421052631578946\n","Train: Epoch = 61 | Loss = 3.3312899849631568 | Accuracy = 0.16\n","Train: Epoch = 62 | Loss = 3.273432731628418 | Accuracy = 0.19384615384615383\n","Train: Epoch = 63 | Loss = 3.22430140321905 | Accuracy = 0.19384615384615383\n","Train: Epoch = 64 | Loss = 3.2167353196577593 | Accuracy = 0.14461538461538462\n","Train: Epoch = 65 | Loss = 3.2165526260029185 | Accuracy = 0.19692307692307692\n","Val: Epoch = 65 | Loss 3.1383620500564575 | Accuracy = 0.16666666666666666\n","Train: Epoch = 66 | Loss = 3.2874972603537818 | Accuracy = 0.19076923076923077\n","Train: Epoch = 67 | Loss = 3.2283776023171167 | Accuracy = 0.20923076923076922\n","Train: Epoch = 68 | Loss = 3.2000450004230845 | Accuracy = 0.16615384615384615\n","Train: Epoch = 69 | Loss = 3.21436223116788 | Accuracy = 0.18769230769230769\n","Train: Epoch = 70 | Loss = 3.1853852488777856 | Accuracy = 0.18769230769230769\n","Val: Epoch = 70 | Loss 3.100283145904541 | Accuracy = 0.17543859649122806\n","Train: Epoch = 71 | Loss = 3.1577436923980713 | Accuracy = 0.16923076923076924\n","Train: Epoch = 72 | Loss = 3.175248796289617 | Accuracy = 0.1753846153846154\n","Train: Epoch = 73 | Loss = 3.1088958220048384 | Accuracy = 0.20923076923076922\n","Train: Epoch = 74 | Loss = 3.1380085294896904 | Accuracy = 0.2123076923076923\n","Train: Epoch = 75 | Loss = 3.156562241640958 | Accuracy = 0.22153846153846155\n","Val: Epoch = 75 | Loss 3.091495931148529 | Accuracy = 0.18421052631578946\n","Train: Epoch = 76 | Loss = 3.1771483421325684 | Accuracy = 0.18461538461538463\n","Train: Epoch = 77 | Loss = 3.225091890855269 | Accuracy = 0.18461538461538463\n","Train: Epoch = 78 | Loss = 3.089704166759144 | Accuracy = 0.24\n","Train: Epoch = 79 | Loss = 3.0814708362926138 | Accuracy = 0.2276923076923077\n","Train: Epoch = 80 | Loss = 3.0993163368918677 | Accuracy = 0.19384615384615383\n","Val: Epoch = 80 | Loss 3.088236093521118 | Accuracy = 0.20175438596491227\n","Train: Epoch = 81 | Loss = 3.039840503172441 | Accuracy = 0.2123076923076923\n","Train: Epoch = 82 | Loss = 3.1192467646165327 | Accuracy = 0.18769230769230769\n","Train: Epoch = 83 | Loss = 3.0904405333779077 | Accuracy = 0.2276923076923077\n","Train: Epoch = 84 | Loss = 3.182111913507635 | Accuracy = 0.18769230769230769\n","Train: Epoch = 85 | Loss = 2.9788289937106045 | Accuracy = 0.2\n","Val: Epoch = 85 | Loss 3.0857561826705933 | Accuracy = 0.21052631578947367\n","Train: Epoch = 86 | Loss = 3.0830889398401435 | Accuracy = 0.20307692307692307\n","Train: Epoch = 87 | Loss = 2.979198607531461 | Accuracy = 0.24615384615384617\n","Train: Epoch = 88 | Loss = 3.066017649390481 | Accuracy = 0.20923076923076922\n","Train: Epoch = 89 | Loss = 3.141794508153742 | Accuracy = 0.20615384615384616\n","Train: Epoch = 90 | Loss = 3.174882932142778 | Accuracy = 0.2123076923076923\n","Val: Epoch = 90 | Loss 3.0926767587661743 | Accuracy = 0.20175438596491227\n","Train: Epoch = 91 | Loss = 3.0637073516845703 | Accuracy = 0.1723076923076923\n","Train: Epoch = 92 | Loss = 3.1039462739771064 | Accuracy = 0.19076923076923077\n","Train: Epoch = 93 | Loss = 3.168347705494274 | Accuracy = 0.2\n","Train: Epoch = 94 | Loss = 3.0713541507720947 | Accuracy = 0.23076923076923078\n","Train: Epoch = 95 | Loss = 3.119020852175626 | Accuracy = 0.20307692307692307\n","Val: Epoch = 95 | Loss 3.071138024330139 | Accuracy = 0.19298245614035087\n","Train: Epoch = 96 | Loss = 3.037012381987138 | Accuracy = 0.19692307692307692\n","Train: Epoch = 97 | Loss = 3.145481738177213 | Accuracy = 0.2\n","Train: Epoch = 98 | Loss = 3.0661143606359307 | Accuracy = 0.2\n","Train: Epoch = 99 | Loss = 3.1104030825875024 | Accuracy = 0.24\n","Train: Epoch = 100 | Loss = 3.07228929346258 | Accuracy = 0.2153846153846154\n","Val: Epoch = 100 | Loss 3.0679734349250793 | Accuracy = 0.20175438596491227\n","Train: Epoch = 101 | Loss = 3.1720618334683506 | Accuracy = 0.24307692307692308\n","Train: Epoch = 102 | Loss = 3.060599587180398 | Accuracy = 0.2\n","Train: Epoch = 103 | Loss = 3.128318418156017 | Accuracy = 0.16\n","Train: Epoch = 104 | Loss = 2.972424767234109 | Accuracy = 0.21846153846153846\n","Train: Epoch = 105 | Loss = 3.0549156882546167 | Accuracy = 0.20615384615384616\n","Val: Epoch = 105 | Loss 3.073722720146179 | Accuracy = 0.20175438596491227\n","Train: Epoch = 106 | Loss = 3.0131385109641333 | Accuracy = 0.20615384615384616\n","Train: Epoch = 107 | Loss = 3.1828513145446777 | Accuracy = 0.17846153846153845\n","Train: Epoch = 108 | Loss = 3.05430024320429 | Accuracy = 0.20615384615384616\n","Train: Epoch = 109 | Loss = 3.1680517196655273 | Accuracy = 0.19384615384615383\n","Train: Epoch = 110 | Loss = 3.070560325275768 | Accuracy = 0.2276923076923077\n","Val: Epoch = 110 | Loss 3.069743812084198 | Accuracy = 0.19298245614035087\n","Train: Epoch = 111 | Loss = 3.0998075008392334 | Accuracy = 0.2246153846153846\n","Train: Epoch = 112 | Loss = 3.239996173165061 | Accuracy = 0.16923076923076924\n","Train: Epoch = 113 | Loss = 3.1667632406408135 | Accuracy = 0.19076923076923077\n","Train: Epoch = 114 | Loss = 2.982450918717818 | Accuracy = 0.19076923076923077\n","Train: Epoch = 115 | Loss = 3.061028848994862 | Accuracy = 0.2153846153846154\n","Val: Epoch = 115 | Loss 3.0594233870506287 | Accuracy = 0.20175438596491227\n","Train: Epoch = 116 | Loss = 3.111017270521684 | Accuracy = 0.1753846153846154\n","Train: Epoch = 117 | Loss = 2.9984794530001553 | Accuracy = 0.22153846153846155\n","Train: Epoch = 118 | Loss = 3.098554589531638 | Accuracy = 0.2153846153846154\n","Train: Epoch = 119 | Loss = 3.145949602127075 | Accuracy = 0.19384615384615383\n","Train: Epoch = 120 | Loss = 3.1056419502605093 | Accuracy = 0.2123076923076923\n","Val: Epoch = 120 | Loss 3.064416766166687 | Accuracy = 0.20175438596491227\n","Train: Epoch = 121 | Loss = 2.9726713570681484 | Accuracy = 0.23692307692307693\n","Train: Epoch = 122 | Loss = 3.075586514039473 | Accuracy = 0.19692307692307692\n","Train: Epoch = 123 | Loss = 3.021369457244873 | Accuracy = 0.24615384615384617\n","Train: Epoch = 124 | Loss = 3.05346510627053 | Accuracy = 0.20307692307692307\n","Train: Epoch = 125 | Loss = 3.070737903768366 | Accuracy = 0.23692307692307693\n","Val: Epoch = 125 | Loss 3.0659972429275513 | Accuracy = 0.18421052631578946\n","Train: Epoch = 126 | Loss = 2.9931852600791236 | Accuracy = 0.23692307692307693\n","Train: Epoch = 127 | Loss = 3.017541430213235 | Accuracy = 0.20923076923076922\n","Train: Epoch = 128 | Loss = 3.0685077147050337 | Accuracy = 0.21846153846153846\n","Train: Epoch = 129 | Loss = 3.0927149815992876 | Accuracy = 0.20923076923076922\n","Train: Epoch = 130 | Loss = 3.249166813763705 | Accuracy = 0.20923076923076922\n","Val: Epoch = 130 | Loss 3.069889187812805 | Accuracy = 0.19298245614035087\n","Train: Epoch = 131 | Loss = 3.0706512061032383 | Accuracy = 0.18769230769230769\n","Train: Epoch = 132 | Loss = 3.030347130515359 | Accuracy = 0.18153846153846154\n","Train: Epoch = 133 | Loss = 3.111805937506936 | Accuracy = 0.20307692307692307\n","Train: Epoch = 134 | Loss = 3.052897323261608 | Accuracy = 0.18461538461538463\n","Train: Epoch = 135 | Loss = 3.1174779371781782 | Accuracy = 0.2123076923076923\n","Val: Epoch = 135 | Loss 3.0581483244895935 | Accuracy = 0.20175438596491227\n","Train: Epoch = 136 | Loss = 3.1126140247691763 | Accuracy = 0.20307692307692307\n","Train: Epoch = 137 | Loss = 3.0052214319055732 | Accuracy = 0.19692307692307692\n","Train: Epoch = 138 | Loss = 2.9727848226373847 | Accuracy = 0.22153846153846155\n","Train: Epoch = 139 | Loss = 2.9668012965809214 | Accuracy = 0.24\n","Train: Epoch = 140 | Loss = 3.106519439003684 | Accuracy = 0.18461538461538463\n","Val: Epoch = 140 | Loss 3.056738555431366 | Accuracy = 0.21052631578947367\n","Train: Epoch = 141 | Loss = 3.08414719321511 | Accuracy = 0.23076923076923078\n","Train: Epoch = 142 | Loss = 3.1150190396742388 | Accuracy = 0.19692307692307692\n","Train: Epoch = 143 | Loss = 3.0835703936490146 | Accuracy = 0.2123076923076923\n","Train: Epoch = 144 | Loss = 3.0628889257257637 | Accuracy = 0.20307692307692307\n","Train: Epoch = 145 | Loss = 3.067891684445468 | Accuracy = 0.20923076923076922\n","Val: Epoch = 145 | Loss 3.058901846408844 | Accuracy = 0.21052631578947367\n","Train: Epoch = 146 | Loss = 3.120373184030706 | Accuracy = 0.20307692307692307\n","Train: Epoch = 147 | Loss = 3.051322200081565 | Accuracy = 0.20923076923076922\n","Train: Epoch = 148 | Loss = 3.08405403657393 | Accuracy = 0.22153846153846155\n","Train: Epoch = 149 | Loss = 3.2045707269148394 | Accuracy = 0.19692307692307692\n","Train: Epoch = 150 | Loss = 3.021929134022106 | Accuracy = 0.24\n","Val: Epoch = 150 | Loss 3.052110195159912 | Accuracy = 0.20175438596491227\n","Train: Epoch = 151 | Loss = 3.126591920852661 | Accuracy = 0.2123076923076923\n","Train: Epoch = 152 | Loss = 3.0421242063695733 | Accuracy = 0.20923076923076922\n","Train: Epoch = 153 | Loss = 3.051039999181574 | Accuracy = 0.18153846153846154\n","Train: Epoch = 154 | Loss = 3.0765398198908027 | Accuracy = 0.2\n","Train: Epoch = 155 | Loss = 2.963985638184981 | Accuracy = 0.23076923076923078\n","Val: Epoch = 155 | Loss 3.0519949793815613 | Accuracy = 0.21052631578947367\n","Train: Epoch = 156 | Loss = 2.967305985364047 | Accuracy = 0.2123076923076923\n","Train: Epoch = 157 | Loss = 3.0714185454628686 | Accuracy = 0.22153846153846155\n","Train: Epoch = 158 | Loss = 2.9494343887675893 | Accuracy = 0.22153846153846155\n","Train: Epoch = 159 | Loss = 3.0176452723416416 | Accuracy = 0.19076923076923077\n","Train: Epoch = 160 | Loss = 3.0373573303222656 | Accuracy = 0.23076923076923078\n","Val: Epoch = 160 | Loss 3.0519784092903137 | Accuracy = 0.20175438596491227\n","Train: Epoch = 161 | Loss = 2.946718866174871 | Accuracy = 0.2123076923076923\n","Train: Epoch = 162 | Loss = 2.992625604976307 | Accuracy = 0.2276923076923077\n","Train: Epoch = 163 | Loss = 2.952938123182817 | Accuracy = 0.2676923076923077\n","Train: Epoch = 164 | Loss = 3.1050127202814277 | Accuracy = 0.2153846153846154\n","Train: Epoch = 165 | Loss = 2.9207860990004106 | Accuracy = 0.20923076923076922\n","Val: Epoch = 165 | Loss 3.0514007806777954 | Accuracy = 0.20175438596491227\n","Train: Epoch = 166 | Loss = 3.0999348813837226 | Accuracy = 0.20615384615384616\n","Train: Epoch = 167 | Loss = 3.047126293182373 | Accuracy = 0.20307692307692307\n","Train: Epoch = 168 | Loss = 3.011884645982222 | Accuracy = 0.23384615384615384\n","Train: Epoch = 169 | Loss = 2.9436331662264736 | Accuracy = 0.21846153846153846\n","Train: Epoch = 170 | Loss = 3.144775477322665 | Accuracy = 0.19692307692307692\n","Val: Epoch = 170 | Loss 3.0511605739593506 | Accuracy = 0.20175438596491227\n","Train: Epoch = 171 | Loss = 3.0432392250407827 | Accuracy = 0.20307692307692307\n","Train: Epoch = 172 | Loss = 3.041086587038907 | Accuracy = 0.20615384615384616\n","Train: Epoch = 173 | Loss = 2.999745585701682 | Accuracy = 0.20307692307692307\n","Train: Epoch = 174 | Loss = 3.0311666185205635 | Accuracy = 0.2276923076923077\n","Train: Epoch = 175 | Loss = 2.962208292701028 | Accuracy = 0.25846153846153846\n","Val: Epoch = 175 | Loss 3.049990236759186 | Accuracy = 0.21052631578947367\n","Train: Epoch = 176 | Loss = 3.072353406385942 | Accuracy = 0.2246153846153846\n","Train: Epoch = 177 | Loss = 3.065000143918124 | Accuracy = 0.20923076923076922\n","Train: Epoch = 178 | Loss = 3.04496786811135 | Accuracy = 0.19692307692307692\n","Train: Epoch = 179 | Loss = 3.0250665057789194 | Accuracy = 0.20615384615384616\n","Train: Epoch = 180 | Loss = 3.034209381450306 | Accuracy = 0.20615384615384616\n","Val: Epoch = 180 | Loss 3.048627495765686 | Accuracy = 0.21052631578947367\n","Train: Epoch = 181 | Loss = 3.0649828260595147 | Accuracy = 0.2276923076923077\n","Train: Epoch = 182 | Loss = 3.0316145420074463 | Accuracy = 0.2123076923076923\n","Train: Epoch = 183 | Loss = 3.007156632163308 | Accuracy = 0.20615384615384616\n","Train: Epoch = 184 | Loss = 2.9856733842329546 | Accuracy = 0.2123076923076923\n","Train: Epoch = 185 | Loss = 3.085509516976096 | Accuracy = 0.19076923076923077\n","Val: Epoch = 185 | Loss 3.0479593873023987 | Accuracy = 0.20175438596491227\n","Train: Epoch = 186 | Loss = 3.0219304128126665 | Accuracy = 0.18153846153846154\n","Train: Epoch = 187 | Loss = 3.004372228275646 | Accuracy = 0.18769230769230769\n","Train: Epoch = 188 | Loss = 3.0306615829467773 | Accuracy = 0.21846153846153846\n","Train: Epoch = 189 | Loss = 3.089080485430631 | Accuracy = 0.20307692307692307\n","Train: Epoch = 190 | Loss = 3.087136680429632 | Accuracy = 0.2246153846153846\n","Val: Epoch = 190 | Loss 3.0474687218666077 | Accuracy = 0.20175438596491227\n","Train: Epoch = 191 | Loss = 3.147371942346746 | Accuracy = 0.2123076923076923\n","Train: Epoch = 192 | Loss = 3.0687888102097944 | Accuracy = 0.2276923076923077\n","Train: Epoch = 193 | Loss = 3.012918862429532 | Accuracy = 0.24615384615384617\n","Train: Epoch = 194 | Loss = 3.098006746985696 | Accuracy = 0.2\n","Train: Epoch = 195 | Loss = 2.957671425559304 | Accuracy = 0.2\n","Val: Epoch = 195 | Loss 3.0465874671936035 | Accuracy = 0.21052631578947367\n","Train: Epoch = 196 | Loss = 3.0804111740805884 | Accuracy = 0.19076923076923077\n","Train: Epoch = 197 | Loss = 3.1026516177437524 | Accuracy = 0.19076923076923077\n","Train: Epoch = 198 | Loss = 3.0657229857011274 | Accuracy = 0.2\n","Train: Epoch = 199 | Loss = 3.014029958031394 | Accuracy = 0.21846153846153846\n","Train: Epoch = 200 | Loss = 3.0201234817504883 | Accuracy = 0.19384615384615383\n","Val: Epoch = 200 | Loss 3.045213520526886 | Accuracy = 0.21929824561403508\n","skipped /content/processed_frames/S1/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S1/take_honey/3, different frame number\n","skipped /content/processed_frames/S1/take_peanut/1, different frame number\n","skipped /content/processed_frames/S3/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S3/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S3/pour_sugar,spoon,cup/4, different frame number\n","skipped /content/processed_frames/S3/stir_spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S4/pour_coffee,spoon,cup/4, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S4/pour_sugar,spoon,cup/3, different frame number\n","skipped /content/processed_frames/S2/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/processed_frames/S2/take_mustard/1, different frame number\n","Train: Epoch = 1 | Loss = 3.617189645767212 | Accuracy = 0.12923076923076923\n","Train: Epoch = 2 | Loss = 3.4277319474653765 | Accuracy = 0.1476923076923077\n","Train: Epoch = 3 | Loss = 3.385525334965099 | Accuracy = 0.15692307692307692\n","Train: Epoch = 4 | Loss = 3.2620978355407715 | Accuracy = 0.16\n","Train: Epoch = 5 | Loss = 3.100963440808383 | Accuracy = 0.19076923076923077\n","Val: Epoch = 5 | Loss 3.065622389316559 | Accuracy = 0.24561403508771928\n","Train: Epoch = 6 | Loss = 3.171861756931652 | Accuracy = 0.17846153846153845\n","Train: Epoch = 7 | Loss = 3.051900863647461 | Accuracy = 0.20615384615384616\n","Train: Epoch = 8 | Loss = 3.042710130864924 | Accuracy = 0.2\n","Train: Epoch = 9 | Loss = 3.1415640224109995 | Accuracy = 0.1753846153846154\n","Train: Epoch = 10 | Loss = 3.04543044350364 | Accuracy = 0.2153846153846154\n","Val: Epoch = 10 | Loss 2.845877528190613 | Accuracy = 0.20175438596491227\n","Train: Epoch = 11 | Loss = 3.002648266878995 | Accuracy = 0.19076923076923077\n","Train: Epoch = 12 | Loss = 3.004534504630349 | Accuracy = 0.1723076923076923\n","Train: Epoch = 13 | Loss = 3.084742611104792 | Accuracy = 0.18153846153846154\n","Train: Epoch = 14 | Loss = 3.078734874725342 | Accuracy = 0.2123076923076923\n","Train: Epoch = 15 | Loss = 2.908085671338168 | Accuracy = 0.26153846153846155\n","Val: Epoch = 15 | Loss 2.7219595313072205 | Accuracy = 0.2543859649122807\n","Train: Epoch = 16 | Loss = 2.9119526689702813 | Accuracy = 0.23384615384615384\n","Train: Epoch = 17 | Loss = 2.7484619400717993 | Accuracy = 0.24615384615384617\n","Train: Epoch = 18 | Loss = 2.9275022853504526 | Accuracy = 0.20307692307692307\n","Train: Epoch = 19 | Loss = 2.856396371668035 | Accuracy = 0.23692307692307693\n","Train: Epoch = 20 | Loss = 2.665071205659346 | Accuracy = 0.2676923076923077\n","Val: Epoch = 20 | Loss 2.4876165986061096 | Accuracy = 0.2982456140350877\n","Train: Epoch = 21 | Loss = 2.7310550646348433 | Accuracy = 0.27692307692307694\n","Train: Epoch = 22 | Loss = 2.602703257040544 | Accuracy = 0.27384615384615385\n","Train: Epoch = 23 | Loss = 2.6832662278955635 | Accuracy = 0.2676923076923077\n","Train: Epoch = 24 | Loss = 2.699802962216464 | Accuracy = 0.28615384615384615\n","Train: Epoch = 25 | Loss = 2.621765201741999 | Accuracy = 0.28307692307692306\n","Val: Epoch = 25 | Loss 2.483935236930847 | Accuracy = 0.34210526315789475\n","Train: Epoch = 26 | Loss = 2.5453427054665307 | Accuracy = 0.3261538461538461\n","Train: Epoch = 27 | Loss = 2.6466834111647173 | Accuracy = 0.3230769230769231\n","Train: Epoch = 28 | Loss = 2.50396407734264 | Accuracy = 0.31384615384615383\n","Train: Epoch = 29 | Loss = 2.501321965997869 | Accuracy = 0.28307692307692306\n","Train: Epoch = 30 | Loss = 2.5749215212735264 | Accuracy = 0.28307692307692306\n","Val: Epoch = 30 | Loss 2.295790731906891 | Accuracy = 0.38596491228070173\n","Train: Epoch = 31 | Loss = 2.5063060413707388 | Accuracy = 0.3415384615384615\n","Train: Epoch = 32 | Loss = 2.5186841921372847 | Accuracy = 0.29846153846153844\n","Train: Epoch = 33 | Loss = 2.510170503096147 | Accuracy = 0.2923076923076923\n","Train: Epoch = 34 | Loss = 2.500936334783381 | Accuracy = 0.3292307692307692\n","Train: Epoch = 35 | Loss = 2.387191403995861 | Accuracy = 0.3230769230769231\n","Val: Epoch = 35 | Loss 2.210975170135498 | Accuracy = 0.37719298245614036\n","Train: Epoch = 36 | Loss = 2.4685655290430244 | Accuracy = 0.2923076923076923\n","Train: Epoch = 37 | Loss = 2.3320292126048696 | Accuracy = 0.31384615384615383\n","Train: Epoch = 38 | Loss = 2.4751046029004184 | Accuracy = 0.3323076923076923\n","Train: Epoch = 39 | Loss = 2.4475908929651435 | Accuracy = 0.3292307692307692\n","Train: Epoch = 40 | Loss = 2.2934753027829258 | Accuracy = 0.32\n","Val: Epoch = 40 | Loss 2.1976152062416077 | Accuracy = 0.3684210526315789\n","Train: Epoch = 41 | Loss = 2.3445936224677344 | Accuracy = 0.3323076923076923\n","Train: Epoch = 42 | Loss = 2.435768712650646 | Accuracy = 0.3169230769230769\n","Train: Epoch = 43 | Loss = 2.2816096435893667 | Accuracy = 0.35384615384615387\n","Train: Epoch = 44 | Loss = 2.3315676125613125 | Accuracy = 0.36923076923076925\n","Train: Epoch = 45 | Loss = 2.3314737623388115 | Accuracy = 0.3384615384615385\n","Val: Epoch = 45 | Loss 2.157173991203308 | Accuracy = 0.39473684210526316\n","Train: Epoch = 46 | Loss = 2.2092845006422563 | Accuracy = 0.40307692307692305\n","Train: Epoch = 47 | Loss = 2.3611865693872627 | Accuracy = 0.36923076923076925\n","Train: Epoch = 48 | Loss = 2.2648724751038984 | Accuracy = 0.3569230769230769\n","Train: Epoch = 49 | Loss = 2.2433041117408057 | Accuracy = 0.3723076923076923\n","Train: Epoch = 50 | Loss = 2.3032561865719883 | Accuracy = 0.36615384615384616\n","Val: Epoch = 50 | Loss 2.093869775533676 | Accuracy = 0.41228070175438597\n","Train: Epoch = 51 | Loss = 2.3960800604386763 | Accuracy = 0.3261538461538461\n","Train: Epoch = 52 | Loss = 2.268463275649331 | Accuracy = 0.38153846153846155\n","Train: Epoch = 53 | Loss = 2.252860253507441 | Accuracy = 0.38461538461538464\n","Train: Epoch = 54 | Loss = 2.2667600349946455 | Accuracy = 0.40307692307692305\n","Train: Epoch = 55 | Loss = 2.124630483714017 | Accuracy = 0.36\n","Val: Epoch = 55 | Loss 2.0750503540039062 | Accuracy = 0.40350877192982454\n","Train: Epoch = 56 | Loss = 2.268975160338662 | Accuracy = 0.35384615384615387\n","Train: Epoch = 57 | Loss = 2.274987372485074 | Accuracy = 0.40615384615384614\n","Train: Epoch = 58 | Loss = 2.1852053945714776 | Accuracy = 0.38769230769230767\n","Train: Epoch = 59 | Loss = 2.1403894424438477 | Accuracy = 0.3723076923076923\n","Train: Epoch = 60 | Loss = 2.146519184112549 | Accuracy = 0.4\n","Val: Epoch = 60 | Loss 2.1002376675605774 | Accuracy = 0.37719298245614036\n","Train: Epoch = 61 | Loss = 2.145179271697998 | Accuracy = 0.39076923076923076\n","Train: Epoch = 62 | Loss = 2.2218679731542412 | Accuracy = 0.37846153846153846\n","Train: Epoch = 63 | Loss = 2.2323182821273804 | Accuracy = 0.36923076923076925\n","Train: Epoch = 64 | Loss = 2.247502326965332 | Accuracy = 0.39076923076923076\n","Train: Epoch = 65 | Loss = 2.1088221073150635 | Accuracy = 0.37538461538461537\n","Val: Epoch = 65 | Loss 2.0529207587242126 | Accuracy = 0.42105263157894735\n","Train: Epoch = 66 | Loss = 2.1935043443333018 | Accuracy = 0.36923076923076925\n","Train: Epoch = 67 | Loss = 2.198640888387507 | Accuracy = 0.36615384615384616\n","Train: Epoch = 68 | Loss = 2.2820416905663232 | Accuracy = 0.36615384615384616\n","Train: Epoch = 69 | Loss = 2.2135981104590674 | Accuracy = 0.38153846153846155\n","Train: Epoch = 70 | Loss = 2.162357221950184 | Accuracy = 0.39692307692307693\n","Val: Epoch = 70 | Loss 2.0630368292331696 | Accuracy = 0.4298245614035088\n","Train: Epoch = 71 | Loss = 2.1820766817439687 | Accuracy = 0.38153846153846155\n","Train: Epoch = 72 | Loss = 2.140034317970276 | Accuracy = 0.37846153846153846\n","Train: Epoch = 73 | Loss = 2.1558886116201226 | Accuracy = 0.35384615384615387\n","Train: Epoch = 74 | Loss = 2.1923562613400547 | Accuracy = 0.37846153846153846\n","Train: Epoch = 75 | Loss = 2.093793110413985 | Accuracy = 0.4123076923076923\n","Val: Epoch = 75 | Loss 2.0660164058208466 | Accuracy = 0.43859649122807015\n","Train: Epoch = 76 | Loss = 2.0998106653040107 | Accuracy = 0.38461538461538464\n","Train: Epoch = 77 | Loss = 2.2137726653705943 | Accuracy = 0.38153846153846155\n","Train: Epoch = 78 | Loss = 2.1290910135615957 | Accuracy = 0.4338461538461538\n","Train: Epoch = 79 | Loss = 2.0876918597654863 | Accuracy = 0.38461538461538464\n","Train: Epoch = 80 | Loss = 2.182764335112138 | Accuracy = 0.37846153846153846\n","Val: Epoch = 80 | Loss 2.0312661230564117 | Accuracy = 0.47368421052631576\n","Train: Epoch = 81 | Loss = 2.194590926170349 | Accuracy = 0.40615384615384614\n","Train: Epoch = 82 | Loss = 2.151112675666809 | Accuracy = 0.39076923076923076\n","Train: Epoch = 83 | Loss = 2.029488455165516 | Accuracy = 0.37538461538461537\n","Train: Epoch = 84 | Loss = 2.1549298113042656 | Accuracy = 0.4153846153846154\n","Train: Epoch = 85 | Loss = 2.1156282858415083 | Accuracy = 0.40307692307692305\n","Val: Epoch = 85 | Loss 2.0279312133789062 | Accuracy = 0.4649122807017544\n","Train: Epoch = 86 | Loss = 2.1618905717676338 | Accuracy = 0.39076923076923076\n","Train: Epoch = 87 | Loss = 2.3035216981714424 | Accuracy = 0.38153846153846155\n","Train: Epoch = 88 | Loss = 2.179643739353527 | Accuracy = 0.4276923076923077\n","Train: Epoch = 89 | Loss = 2.0151497667486016 | Accuracy = 0.4369230769230769\n","Train: Epoch = 90 | Loss = 2.0872434052554043 | Accuracy = 0.4123076923076923\n","Val: Epoch = 90 | Loss 2.0209648609161377 | Accuracy = 0.4473684210526316\n","Train: Epoch = 91 | Loss = 2.0403658693486992 | Accuracy = 0.41846153846153844\n","Train: Epoch = 92 | Loss = 2.1716993071816186 | Accuracy = 0.40615384615384614\n","Train: Epoch = 93 | Loss = 2.1718538240952925 | Accuracy = 0.3630769230769231\n","Train: Epoch = 94 | Loss = 2.218106345696883 | Accuracy = 0.4123076923076923\n","Train: Epoch = 95 | Loss = 2.1411070932041514 | Accuracy = 0.37538461538461537\n","Val: Epoch = 95 | Loss 1.998680204153061 | Accuracy = 0.4473684210526316\n","Train: Epoch = 96 | Loss = 2.1663366014307197 | Accuracy = 0.39384615384615385\n","Train: Epoch = 97 | Loss = 2.0616207231174815 | Accuracy = 0.4276923076923077\n","Train: Epoch = 98 | Loss = 2.090746749531139 | Accuracy = 0.4246153846153846\n","Train: Epoch = 99 | Loss = 2.270984487100081 | Accuracy = 0.4\n","Train: Epoch = 100 | Loss = 2.043299013918096 | Accuracy = 0.4430769230769231\n","Val: Epoch = 100 | Loss 1.9910532236099243 | Accuracy = 0.45614035087719296\n","Train: Epoch = 101 | Loss = 2.0981276577169243 | Accuracy = 0.40615384615384614\n","Train: Epoch = 102 | Loss = 2.1566492319107056 | Accuracy = 0.39692307692307693\n","Train: Epoch = 103 | Loss = 2.08574209430001 | Accuracy = 0.40307692307692305\n","Train: Epoch = 104 | Loss = 2.149080688303167 | Accuracy = 0.40923076923076923\n","Train: Epoch = 105 | Loss = 2.1329226818951694 | Accuracy = 0.38461538461538464\n","Val: Epoch = 105 | Loss 1.9944657385349274 | Accuracy = 0.4649122807017544\n","Train: Epoch = 106 | Loss = 2.078145991672169 | Accuracy = 0.41846153846153844\n","Train: Epoch = 107 | Loss = 2.0309042605486782 | Accuracy = 0.4369230769230769\n","Train: Epoch = 108 | Loss = 2.1481053829193115 | Accuracy = 0.37538461538461537\n","Train: Epoch = 109 | Loss = 2.167585708878257 | Accuracy = 0.39076923076923076\n","Train: Epoch = 110 | Loss = 2.1439776854081587 | Accuracy = 0.4153846153846154\n","Val: Epoch = 110 | Loss 1.9925215244293213 | Accuracy = 0.47368421052631576\n","Train: Epoch = 111 | Loss = 2.027582038532604 | Accuracy = 0.4153846153846154\n","Train: Epoch = 112 | Loss = 2.1736753312024204 | Accuracy = 0.39692307692307693\n","Train: Epoch = 113 | Loss = 2.166446024721319 | Accuracy = 0.4123076923076923\n","Train: Epoch = 114 | Loss = 2.165830059485002 | Accuracy = 0.4123076923076923\n","Train: Epoch = 115 | Loss = 2.142899209802801 | Accuracy = 0.38461538461538464\n","Val: Epoch = 115 | Loss 1.9848672151565552 | Accuracy = 0.45614035087719296\n","Train: Epoch = 116 | Loss = 2.2224640412764116 | Accuracy = 0.38769230769230767\n","Train: Epoch = 117 | Loss = 2.134413079781966 | Accuracy = 0.4338461538461538\n","Train: Epoch = 118 | Loss = 2.107253583994779 | Accuracy = 0.4\n","Train: Epoch = 119 | Loss = 2.05443677035245 | Accuracy = 0.4369230769230769\n","Train: Epoch = 120 | Loss = 2.1520127925005825 | Accuracy = 0.39076923076923076\n","Val: Epoch = 120 | Loss 1.9959669411182404 | Accuracy = 0.43859649122807015\n","Train: Epoch = 121 | Loss = 2.025451887737621 | Accuracy = 0.42153846153846153\n","Train: Epoch = 122 | Loss = 2.148436340418729 | Accuracy = 0.4153846153846154\n","Train: Epoch = 123 | Loss = 2.1267272450707178 | Accuracy = 0.40923076923076923\n","Train: Epoch = 124 | Loss = 2.105739116668701 | Accuracy = 0.40923076923076923\n","Train: Epoch = 125 | Loss = 2.1865624406120996 | Accuracy = 0.38461538461538464\n","Val: Epoch = 125 | Loss 1.9857369363307953 | Accuracy = 0.4473684210526316\n","Train: Epoch = 126 | Loss = 2.2374550104141235 | Accuracy = 0.37846153846153846\n","Train: Epoch = 127 | Loss = 2.1163954084569756 | Accuracy = 0.40307692307692305\n","Train: Epoch = 128 | Loss = 2.1369572444395586 | Accuracy = 0.39692307692307693\n","Train: Epoch = 129 | Loss = 2.1670091694051568 | Accuracy = 0.4153846153846154\n","Train: Epoch = 130 | Loss = 2.1489143696698276 | Accuracy = 0.38153846153846155\n","Val: Epoch = 130 | Loss 2.0040051639080048 | Accuracy = 0.4298245614035088\n","Train: Epoch = 131 | Loss = 2.183823065324263 | Accuracy = 0.39076923076923076\n","Train: Epoch = 132 | Loss = 2.1353473338213833 | Accuracy = 0.39384615384615385\n","Train: Epoch = 133 | Loss = 2.1473427685824307 | Accuracy = 0.38461538461538464\n","Train: Epoch = 134 | Loss = 2.078045975078236 | Accuracy = 0.41846153846153844\n","Train: Epoch = 135 | Loss = 2.06797410141338 | Accuracy = 0.37846153846153846\n","Val: Epoch = 135 | Loss 1.981524109840393 | Accuracy = 0.4298245614035088\n","Train: Epoch = 136 | Loss = 2.1151836677031084 | Accuracy = 0.4153846153846154\n","Train: Epoch = 137 | Loss = 2.1389114531603726 | Accuracy = 0.40307692307692305\n","Train: Epoch = 138 | Loss = 2.12836614522067 | Accuracy = 0.36615384615384616\n","Train: Epoch = 139 | Loss = 2.000246600671248 | Accuracy = 0.4123076923076923\n","Train: Epoch = 140 | Loss = 2.0917374870993872 | Accuracy = 0.4307692307692308\n","Val: Epoch = 140 | Loss 1.970625102519989 | Accuracy = 0.42105263157894735\n","Train: Epoch = 141 | Loss = 2.095262549140237 | Accuracy = 0.40923076923076923\n","Train: Epoch = 142 | Loss = 2.0455982143228706 | Accuracy = 0.4430769230769231\n","Train: Epoch = 143 | Loss = 2.1027335687117144 | Accuracy = 0.40615384615384614\n","Train: Epoch = 144 | Loss = 2.0889735221862793 | Accuracy = 0.41846153846153844\n","Train: Epoch = 145 | Loss = 2.032712697982788 | Accuracy = 0.44\n","Val: Epoch = 145 | Loss 1.9737453162670135 | Accuracy = 0.4473684210526316\n","Train: Epoch = 146 | Loss = 2.1823001233014194 | Accuracy = 0.38769230769230767\n","Train: Epoch = 147 | Loss = 2.275625564835288 | Accuracy = 0.38769230769230767\n","Train: Epoch = 148 | Loss = 2.1144148219715464 | Accuracy = 0.42153846153846153\n","Train: Epoch = 149 | Loss = 2.1024061007933184 | Accuracy = 0.3723076923076923\n","Train: Epoch = 150 | Loss = 2.015010107647289 | Accuracy = 0.42153846153846153\n","Val: Epoch = 150 | Loss 1.964458853006363 | Accuracy = 0.4473684210526316\n"],"name":"stdout"}]}]}