{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9BtXLSWZ_wL"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n",
    "                                RandomHorizontalFlip)\n",
    "import torch.nn as nn\n",
    "from twoStreamModel import *\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from makeDataset import *\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "DEVICE = 'cuda'     # gpu acceleration\n",
    "\n",
    "# version is a name for the run\n",
    "# a different folder will be created for every version\n",
    "def main_run(version, flowModel, rgbModel, stackSize, seqLen, memSize, trainDatasetDir, outDir,\n",
    "             trainBatchSize, valBatchSize, lr1, numEpochs, decay_step, decay_factor):\n",
    "    \n",
    "    num_classes = 61     # gtea61 dataset\n",
    "    model_folder = os.path.join(\"./\", outDir, version)\n",
    "\n",
    "    # Create the dir\n",
    "    print(f\"Checking directory {model_folder}\")\n",
    "    if os.path.exists(model_folder):\n",
    "        print('Dir {} exists!'.format(model_folder))\n",
    "        sys.exit()\n",
    "    print(f\"Creating directory{model_folder}\")\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "    # Log files\n",
    "    print(f\"Creating log files\")\n",
    "    train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n",
    "    train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n",
    "    val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n",
    "    val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')\n",
    "\n",
    "    # ImageNet mean and std\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # Train val partitioning\n",
    "    train_usr = [\"S1\", \"S3\", \"S4\"]\n",
    "    val_usr = [\"S2\"]\n",
    "\n",
    "\n",
    "    normalize = Normalize(mean=mean, std=std)\n",
    "\n",
    "    spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
    "                                 ToTensor(), normalize])\n",
    "    # train dataset\n",
    "    print(f\"Defining train dataset\")\n",
    "    vid_seq_train = makeDataset(trainDatasetDir, train_usr, spatial_transform,\n",
    "                               stackSize=stackSize, seqLen=seqLen)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n",
    "                            shuffle=True, num_workers=4, pin_memory=True)\n",
    "    \n",
    "\n",
    "    # val dataset\n",
    "    print(f\"Defining validation dataset\")\n",
    "    vid_seq_val = makeDataset(trainDatasetDir, val_usr,\n",
    "                                   spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n",
    "                                   stackSize=stackSize, phase=\"val\", seqLen=seqLen)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n",
    "                                shuffle=False, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    valSamples = vid_seq_val.__len__()\n",
    "\n",
    "\n",
    "    # model\n",
    "    print(\"Building model\")\n",
    "    model = twoStreamAttentionModel(flowModel=flowModel, frameModel=rgbModel, stackSize=stackSize, memSize=memSize,         # see twoStreamModel.py\n",
    "                                    num_classes=num_classes)\n",
    "    \n",
    "    print(\"Setting trainable parameters\")\n",
    "    for params in model.parameters():           # initially freeze all layers\n",
    "        params.requires_grad = False\n",
    "\n",
    "    model.train(False)\n",
    "    train_params = []\n",
    "\n",
    "    for params in model.classifier.parameters():    # unfreeze classifier layer (the layer that joins the two models outputs)\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "\n",
    "    for params in model.frameModel.lstm_cell.parameters():  # unfreeze lstm layer of the frame model\n",
    "        train_params += [params]\n",
    "        params.requires_grad = True\n",
    "\n",
    "    for params in model.frameModel.resNet.layer4[0].conv1.parameters():     #unfreeze layer 4\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "\n",
    "    for params in model.frameModel.resNet.layer4[0].conv2.parameters():\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "\n",
    "    for params in model.frameModel.resNet.layer4[1].conv1.parameters():\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "\n",
    "    for params in model.frameModel.resNet.layer4[1].conv2.parameters():\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "\n",
    "    for params in model.frameModel.resNet.layer4[2].conv1.parameters():\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "    #\n",
    "    for params in model.frameModel.resNet.layer4[2].conv2.parameters():\n",
    "        params.requires_grad = True\n",
    "        train_params += [params]\n",
    "    #\n",
    "    for params in model.frameModel.resNet.fc.parameters():              # unfreeze last fully connected layer of frame model \n",
    "        params.requires_grad = True                                     # (I still don't know why, because in the joining of the two models, this layer is skipped)\n",
    "        train_params += [params]                                        \n",
    "\n",
    "    base_params = []\n",
    "    for params in model.flowModel.layer4.parameters():              # unfreeze layer 4 of flow model\n",
    "        base_params += [params]\n",
    "        params.requires_grad = True\n",
    "\n",
    "    print(\"Moving model to GPU\")\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    trainSamples = vid_seq_train.__len__()\n",
    "    min_accuracy = 0\n",
    "\n",
    "    print(\"Defining loss function, optimizer and scheduler\")\n",
    "    loss_fn = nn.CrossEntropyLoss()     # loss function\n",
    "    optimizer_fn = torch.optim.SGD([    # optimizer\n",
    "        {'params': train_params},\n",
    "        {'params': base_params, 'lr': 1e-4},  # 1e-4\n",
    "    ], lr=lr1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    #scheduler\n",
    "    optim_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_fn, step_size=decay_step, gamma=decay_factor)\n",
    "    train_iter = 0\n",
    "\n",
    "    print(\"Training begun\")\n",
    "    # TRAIN PROCEDURE\n",
    "    for epoch in range(numEpochs):\n",
    "        optim_scheduler.step()\n",
    "        epoch_loss = 0\n",
    "        numCorrTrain = 0\n",
    "        iterPerEpoch = 0\n",
    "        model.classifier.train(True)\n",
    "        model.flowModel.layer4.train(True)\n",
    "\n",
    "\n",
    "        start = time.time()\n",
    "        for j, (inputFrame, inputMMaps, inputFlow, targets) in enumerate(train_loader):\n",
    "            \n",
    "            print(f\"step {j} / {int(np.floor(trainSamples/trainBatchSize))}\")\n",
    "            \n",
    "            train_iter += 1\n",
    "            iterPerEpoch += 1\n",
    "            optimizer_fn.zero_grad()                                                # put gradients to zero\n",
    "            inputVariableFlow = Variable(inputFlow.to(DEVICE))\n",
    "            inputVariableFrame = Variable(inputFrame.permute(1, 0, 2, 3, 4).to(DEVICE))\n",
    "            labelVariable = Variable(targets.to(DEVICE))\n",
    "            #print(\"predict\")\n",
    "            output_label = model(inputVariableFlow, inputVariableFrame)         # predict\n",
    "            loss = loss_fn(F.log_softmax(output_label, dim=1), labelVariable)   # compute loss\n",
    "            #print(\"backprop\")\n",
    "            loss.backward()                                                     \n",
    "            optimizer_fn.step()\n",
    "            #print(\"accuracy\")\n",
    "            _, predicted = torch.max(output_label.data, 1)                  \n",
    "            numCorrTrain += (predicted == targets.to(DEVICE)).sum()             # counting number of correct predictions\n",
    "            epoch_loss += loss.data.item()  \n",
    "\n",
    "        \n",
    "        avg_loss = epoch_loss / iterPerEpoch                                    # computing average per epoch loss\n",
    "        trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n",
    "        print('Average training loss after {} epoch = {} '.format(epoch + 1, avg_loss))\n",
    "        print('Training accuracy after {} epoch = {}% '.format(epoch + 1, trainAccuracy))\n",
    "        train_log_loss.write('Training loss after {} epoch = {}\\n'.format(epoch + 1, avg_loss))             # log file\n",
    "        train_log_acc.write('Training accuracy after {} epoch = {}\\n'.format(epoch + 1, trainAccuracy))     # log file\n",
    "        print(f\"Elapsed : {time.time()-start}\")\n",
    "\n",
    "        # VALIDATION\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model.train(False)\n",
    "            val_loss_epoch = 0\n",
    "            val_iter = 0\n",
    "            numCorr = 0\n",
    "            for j, (inputFrame, inputMMaps, inputFlow, targets) in enumerate(val_loader):\n",
    "                if j % 1 == 0:\n",
    "                    print(f\"step {j} / {int(np.floor(vid_seq_val.__len__()/valBatchSize))}\")\n",
    "\n",
    "                val_iter += 1\n",
    "                inputVariableFlow = Variable(inputFlow.to(DEVICE))\n",
    "                inputVariableFrame = Variable(inputFrame.permute(1, 0, 2, 3, 4).to(DEVICE))\n",
    "                labelVariable = Variable(targets.to(DEVICE))\n",
    "                output_label = model(inputVariableFlow, inputVariableFrame)\n",
    "                loss = loss_fn(F.log_softmax(output_label, dim=1), labelVariable)\n",
    "                val_loss_epoch += loss.data.item()\n",
    "                _, predicted = torch.max(output_label.data, 1)\n",
    "                numCorr += (predicted == labelVariable.data).sum()\n",
    "            val_accuracy = (numCorr.item() / valSamples) * 100\n",
    "            avg_val_loss = val_loss_epoch / val_iter\n",
    "            print('Val Loss after {} epochs, loss = {}'.format(epoch + 1, avg_val_loss))\n",
    "            print('Val Accuracy after {} epochs = {}%'.format(epoch + 1, val_accuracy))\n",
    "            val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))       # log file\n",
    "            val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))   # log file\n",
    "            if val_accuracy > min_accuracy:\n",
    "                save_path_model = (model_folder + '/model_twoStream_state_dict.pth')                    # every epoch, check if the val accuracy is improved, if so, save that model\n",
    "                torch.save(model.state_dict(), save_path_model)                                         # in that way, even if the model overfit, you will get always the best model\n",
    "                min_accuracy = val_accuracy                                                             # in this way you don't have to care too much about the number of epochs\n",
    "\n",
    "    train_log_loss.close()\n",
    "    train_log_acc.close()\n",
    "    val_log_acc.close()\n",
    "    val_log_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"two_stream\"            # progress are saved inside this folder\n",
    "rgbModel = \"/saved_models/model_rgb_state_dict.pth\"\n",
    "flowModel = \"/saved_models/model_flow_state_dict.pth\"\n",
    "trainDatasetDir = \"/content/\"\n",
    "outDir = \"results\"    # root of \"version\" folder\n",
    "stackSize = 5                   # number of flow frame processed in the flow model\n",
    "seqLen = 7                    # number of rgb frames processed in the frame model\n",
    "trainBatchSize = 32\n",
    "valBatchSize = 32\n",
    "numEpochs = 250\n",
    "lr1 = 1e-2\n",
    "decay_step = 1\n",
    "decay_factor = 0.99\n",
    "memSize=512\n",
    "\n",
    "main_run(version, flowModel, rgbModel, stackSize, seqLen, memSize, trainDatasetDir, outDir,\n",
    "             trainBatchSize, valBatchSize, lr1, numEpochs, decay_step, decay_factor)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ego-rnn-two-streams.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b6fe0571cef4b119156df18147a4dad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b38adb43ae340fb93878d1844f7b75b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_51b289fd92ad44fca7cedfa4a9e3003f",
      "value": " 83.3M/83.3M [03:45&lt;00:00, 387kB/s]"
     }
    },
    "1347e4236c924ab886eb84aafa11bc14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "228ecbc820154d469d3f0b46ed39ce14": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "376f6bc1ea78422e988f55fe6840b613": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51b289fd92ad44fca7cedfa4a9e3003f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "651150aa9b3e4e8c977e77e8e6bd27f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_228ecbc820154d469d3f0b46ed39ce14",
      "max": 87306240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1347e4236c924ab886eb84aafa11bc14",
      "value": 87306240
     }
    },
    "7b38adb43ae340fb93878d1844f7b75b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e317a13670a4926b03295c72fab4f26": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_651150aa9b3e4e8c977e77e8e6bd27f9",
       "IPY_MODEL_0b6fe0571cef4b119156df18147a4dad"
      ],
      "layout": "IPY_MODEL_376f6bc1ea78422e988f55fe6840b613"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
