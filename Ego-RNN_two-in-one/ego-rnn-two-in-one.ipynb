{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ego-rnn-two-in-one.ipynb","provenance":[],"mount_file_id":"1m-YqEwt85DGVO10683ClI1ssSU5Zlyxm","authorship_tag":"ABX9TyNXD496EKA1886bwFAG1ZB4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Jaw85zJroGKw","colab_type":"code","outputId":"0a33995c-0d59-4462-893b-93225593fed4","executionInfo":{"status":"ok","timestamp":1591086852744,"user_tz":-120,"elapsed":15114,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9MbVd2LXo83h","colab_type":"code","outputId":"8ac8b9bb-4160-4f60-ec64-4e98b3c4b2a9","executionInfo":{"status":"ok","timestamp":1591087281004,"user_tz":-120,"elapsed":424029,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd \"/content/\"\n","!wget -O \"frames.tar.xz\" \"https://www.dropbox.com/s/etj53uan64h5csc/processed_frames.tar.xz?dl=0\"\n","!wget -O \"flow_x.tar.xz\" \"https://www.dropbox.com/s/i5e6rey93sseogv/flow_x_processed.tar.xz?dl=0\"\n","!wget -O \"flow_y.tar.xz\" \"https://www.dropbox.com/s/4e5msv6bbm9rgn6/flow_y_processed.tar.xz?dl=0\"\n","\n","!tar \"xf\" \"frames.tar.xz\" \n","!tar \"xf\" \"flow_x.tar.xz\" \n","!tar \"xf\" \"flow_y.tar.xz\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","--2020-06-02 08:34:18--  https://www.dropbox.com/s/etj53uan64h5csc/processed_frames.tar.xz?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/etj53uan64h5csc/processed_frames.tar.xz [following]\n","--2020-06-02 08:34:19--  https://www.dropbox.com/s/raw/etj53uan64h5csc/processed_frames.tar.xz\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com/cd/0/inline/A45fdYMcSi4freFInajE-lUpO8frUFEczK5MwOO-ixdYKNNp8yZxMXPjHVDiJEbSJ0Esf4anYpPUXR5xMp168VVZxbP4CHdPoMcbxYATImxlPuTOsE-pJGsd_gV6pl625nA/file# [following]\n","--2020-06-02 08:34:19--  https://uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com/cd/0/inline/A45fdYMcSi4freFInajE-lUpO8frUFEczK5MwOO-ixdYKNNp8yZxMXPjHVDiJEbSJ0Esf4anYpPUXR5xMp168VVZxbP4CHdPoMcbxYATImxlPuTOsE-pJGsd_gV6pl625nA/file\n","Resolving uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com (uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n","Connecting to uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com (uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: /cd/0/inline2/A44SbeJSMM7iyk8Kr-VyxZPT4jiUov-dWrWRx4IeXocYv48sCyA3eE0_hQtJSsUJot5wonVTdyvk6NwX7O7OMsdIHf6b6MuVR3Wa68LL5htUxJ6JBcfO5IAt5GFXVPfaAVhlWpP3rIy68FdfqUn1eiO_tusAykr6BHiId4M_uEgQfHS2N39HUnwHNM4E7q99vWmq15JDolyhwyJqVIjG-OgF4P1jC5CZlp6LsAHPdcvjUqntFSyCb4XMiqTHvLOq4dNkkcogufiJ_4qNZbmJPY1UHU8DbGJ7qfnsjw8mGNmQrxxBEaIApFmNNCb9umJnMvZqlp2uwY1-l2zoLicKTVYsgprILsbbp3BVw0HzHpXbdw/file [following]\n","--2020-06-02 08:34:20--  https://uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com/cd/0/inline2/A44SbeJSMM7iyk8Kr-VyxZPT4jiUov-dWrWRx4IeXocYv48sCyA3eE0_hQtJSsUJot5wonVTdyvk6NwX7O7OMsdIHf6b6MuVR3Wa68LL5htUxJ6JBcfO5IAt5GFXVPfaAVhlWpP3rIy68FdfqUn1eiO_tusAykr6BHiId4M_uEgQfHS2N39HUnwHNM4E7q99vWmq15JDolyhwyJqVIjG-OgF4P1jC5CZlp6LsAHPdcvjUqntFSyCb4XMiqTHvLOq4dNkkcogufiJ_4qNZbmJPY1UHU8DbGJ7qfnsjw8mGNmQrxxBEaIApFmNNCb9umJnMvZqlp2uwY1-l2zoLicKTVYsgprILsbbp3BVw0HzHpXbdw/file\n","Reusing existing connection to uce50640811b9e47e74683647a9e.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3579197744 (3.3G) [application/octet-stream]\n","Saving to: ‘frames.tar.xz’\n","\n","frames.tar.xz       100%[===================>]   3.33G  48.8MB/s    in 70s     \n","\n","2020-06-02 08:35:31 (48.4 MB/s) - ‘frames.tar.xz’ saved [3579197744/3579197744]\n","\n","--2020-06-02 08:35:33--  https://www.dropbox.com/s/i5e6rey93sseogv/flow_x_processed.tar.xz?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/i5e6rey93sseogv/flow_x_processed.tar.xz [following]\n","--2020-06-02 08:35:33--  https://www.dropbox.com/s/raw/i5e6rey93sseogv/flow_x_processed.tar.xz\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com/cd/0/inline/A47H2FIe_XGq9UnfCFO-OYEgl6lfFEXWM4PgBGKpCNScGrXXkED9p4kCMOq9iSWq9XhBuTN2E6tOYlBSUUVdF0mPENZZhqwxN04foh1JouXvTH3KXZdFaYpKK4658tLbMb4/file# [following]\n","--2020-06-02 08:35:33--  https://ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com/cd/0/inline/A47H2FIe_XGq9UnfCFO-OYEgl6lfFEXWM4PgBGKpCNScGrXXkED9p4kCMOq9iSWq9XhBuTN2E6tOYlBSUUVdF0mPENZZhqwxN04foh1JouXvTH3KXZdFaYpKK4658tLbMb4/file\n","Resolving ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com (ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n","Connecting to ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com (ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: /cd/0/inline2/A44uuA3RGRxAcwpEZjd4L2cKwqFpjP3mCNkIZJLoZr14uVaBvpMFLl0BHAEV8e1o2hTSgXD-CTxSvT8vztukyFa3V20U09EWDzFdGpGld9DDbhcFZ4yhkG_am0IacGJd71n1WcaJ5bCjHHFu6KqHSXJoVIlVxbwquYm6bM3cHOQzPb6gqVrQVvE_vdBDYDJLK7xavxQSUSOGkhTHAS0cQVyCrlaLCYKgMN7PtkRzLEhJKwP42NaNcGbK7er1p4IpIHMwtVoH_wzK-HIvkahB5m-5T5SJrmDBvB7hs8aU1vcThivuv3kAH7Ls327jDszljYvzDHhmOJDxZEsyc303EmE4340ArHE1bbtB-w89HnuziA/file [following]\n","--2020-06-02 08:35:34--  https://ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com/cd/0/inline2/A44uuA3RGRxAcwpEZjd4L2cKwqFpjP3mCNkIZJLoZr14uVaBvpMFLl0BHAEV8e1o2hTSgXD-CTxSvT8vztukyFa3V20U09EWDzFdGpGld9DDbhcFZ4yhkG_am0IacGJd71n1WcaJ5bCjHHFu6KqHSXJoVIlVxbwquYm6bM3cHOQzPb6gqVrQVvE_vdBDYDJLK7xavxQSUSOGkhTHAS0cQVyCrlaLCYKgMN7PtkRzLEhJKwP42NaNcGbK7er1p4IpIHMwtVoH_wzK-HIvkahB5m-5T5SJrmDBvB7hs8aU1vcThivuv3kAH7Ls327jDszljYvzDHhmOJDxZEsyc303EmE4340ArHE1bbtB-w89HnuziA/file\n","Reusing existing connection to ucc1a038cbf5adda1dfd1c92b5f3.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 386550028 (369M) [application/octet-stream]\n","Saving to: ‘flow_x.tar.xz’\n","\n","flow_x.tar.xz       100%[===================>] 368.64M  51.3MB/s    in 7.1s    \n","\n","2020-06-02 08:35:42 (51.7 MB/s) - ‘flow_x.tar.xz’ saved [386550028/386550028]\n","\n","--2020-06-02 08:35:43--  https://www.dropbox.com/s/4e5msv6bbm9rgn6/flow_y_processed.tar.xz?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/4e5msv6bbm9rgn6/flow_y_processed.tar.xz [following]\n","--2020-06-02 08:35:44--  https://www.dropbox.com/s/raw/4e5msv6bbm9rgn6/flow_y_processed.tar.xz\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com/cd/0/inline/A45Q804pOVcr9MUzGv_-fDfqn2ebQ5lFtwsLA2zZ9Clx6qUgOYB4LF0xqCrJZemZO0lKAaM30JSUl7CfiCrEZlKjmaSoO5agC1zGnJonxa-2hFPEKRP-INcJQbBb6_aha5o/file# [following]\n","--2020-06-02 08:35:44--  https://ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com/cd/0/inline/A45Q804pOVcr9MUzGv_-fDfqn2ebQ5lFtwsLA2zZ9Clx6qUgOYB4LF0xqCrJZemZO0lKAaM30JSUl7CfiCrEZlKjmaSoO5agC1zGnJonxa-2hFPEKRP-INcJQbBb6_aha5o/file\n","Resolving ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com (ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n","Connecting to ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com (ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: /cd/0/inline2/A46Iukgt5UsI1HyGc3f37BpdKnMTyDYCGZQ65h3qq6J-Xu4EHcOpqpxJLmhmOuxl8D0FEYf082KKl-JtO-c1RPczDL7NVab2zg0ie7xdDwwGpj9vH87rYOXMm79lub_VNly6jNXB0srzPyi0xohbAAxWbGmc_FG5u9MqIJH9Ah0rNVSYz68GUc9-2_mzGoWWUwX8eusciw0XWTCeMb2GIr85K1lWpv_l29KyltDfRfP5SnLzR6jvk5TwPpbOB4aG1c37_avTjhlWi-VbQuVMEd2lcGmRZ1tQLt_pMb6-d1VJT0-lbYPkyFbS52jR5P8Rgt_7fAuWbzmzlekJ0Mb9FZSo3uwO_PiQD966vVUVwl-etw/file [following]\n","--2020-06-02 08:35:45--  https://ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com/cd/0/inline2/A46Iukgt5UsI1HyGc3f37BpdKnMTyDYCGZQ65h3qq6J-Xu4EHcOpqpxJLmhmOuxl8D0FEYf082KKl-JtO-c1RPczDL7NVab2zg0ie7xdDwwGpj9vH87rYOXMm79lub_VNly6jNXB0srzPyi0xohbAAxWbGmc_FG5u9MqIJH9Ah0rNVSYz68GUc9-2_mzGoWWUwX8eusciw0XWTCeMb2GIr85K1lWpv_l29KyltDfRfP5SnLzR6jvk5TwPpbOB4aG1c37_avTjhlWi-VbQuVMEd2lcGmRZ1tQLt_pMb6-d1VJT0-lbYPkyFbS52jR5P8Rgt_7fAuWbzmzlekJ0Mb9FZSo3uwO_PiQD966vVUVwl-etw/file\n","Reusing existing connection to ucb455fc983963c875c7762e9c98.dl.dropboxusercontent.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 392677964 (374M) [application/octet-stream]\n","Saving to: ‘flow_y.tar.xz’\n","\n","flow_y.tar.xz       100%[===================>] 374.49M  63.5MB/s    in 6.0s    \n","\n","2020-06-02 08:35:52 (62.0 MB/s) - ‘flow_y.tar.xz’ saved [392677964/392677964]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WoIjyKqqoWky","colab_type":"code","outputId":"75e3f376-28cb-47bf-f0f9-8dea6567ad51","executionInfo":{"status":"ok","timestamp":1591102774035,"user_tz":-120,"elapsed":958,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd \"/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yv7MIHK2nvBv","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","from objectAttentionModelConvLSTM import *\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n","                                RandomHorizontalFlip)\n","from makeDataset import *\n","import argparse\n","import sys\n","import time\n","\n","DEVICE = \"cuda\"\n","VAL_FREQUENCY = 5"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h22nxHvBn0dV","colab_type":"code","colab":{}},"source":["def mmaps_preparation(data, threshold):\n","    maps = []\n","    for i in range(data.shape[0]):\n","        tensor = data[i]\n","        tensor = F.interpolate(tensor, size=(7, 7), mode='bilinear')\n","        tensor[tensor > threshold] = 1\n","        tensor[tensor <= threshold] = 0\n","        maps.append(tensor)\n","\n","    maps = torch.stack(maps, 0).squeeze(2)\n","    bz, nc, h, w = maps.size()\n","    maps = maps.view(bz, nc, h * w)\n","\n","    return maps\n","\n","\n","def loss_ms_fn(ms_out, map_out):\n","    final_loss = F.binary_cross_entropy(ms_out, map_out.to(DEVICE))\n","    # final_loss = F.soft_margin_loss(ms_out, map_out.to(DEVICE))\n","    # final_loss = F.mse_loss(ms_out, map_out.to(DEVICE))\n","    # final_loss = F.kl_div(ms_out, map_out.to(DEVICE))\n","\n","    print(\"MS loss: %f\" % final_loss)\n","    return final_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsVTJqNbnngm","colab_type":"code","colab":{}},"source":["def main_run(version, stage, train_data_dir, stage1_dict, out_dir, seqLen, trainBatchSize,\n","             valBatchSize, numEpochs, lr1, decay_factor, decay_step, mem_size):\n","    num_classes = 61\n","\n","    model_folder = os.path.join(\"./\", out_dir, version)\n","\n","    if os.path.exists(model_folder):\n","        print('Directory {} exists!'.format(model_folder))\n","        sys.exit()\n","    os.makedirs(model_folder)\n","\n","    train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","    train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","    val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","    val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')\n","\n","    # Train val partitioning\n","    train_usr = [\"S1\", \"S3\", \"S4\"]\n","    val_usr = [\"S2\"]\n","\n","    # Data loader\n","    normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    spatial_transform = Compose(\n","        [Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n","         ToTensor(), normalize])\n","\n","    vid_seq_train = makeDataset(train_data_dir, train_usr,\n","                                spatial_transform=spatial_transform, seqLen=seqLen)\n","\n","    train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n","                                               shuffle=True, num_workers=4, pin_memory=True)\n","\n","    vid_seq_val = makeDataset(train_data_dir, val_usr,\n","                              spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n","                              seqLen=seqLen, phase=\"test\")\n","\n","    val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n","                                             shuffle=False, num_workers=2, pin_memory=True)\n","\n","    train_params = []\n","\n","    # stage 1: train only lstm\n","    if stage == 1:\n","\n","        model = attentionModel(num_classes=num_classes, mem_size=mem_size)\n","        model.train(False)\n","        for params in model.parameters():\n","            params.requires_grad = False\n","\n","    # stage 2: train lstm, layer4, spatial attention and final fc\n","    if stage > 1:\n","        model = attentionModel(num_classes=num_classes, mem_size=mem_size)\n","        model.load_state_dict(torch.load(stage1_dict), strict=False)  # pretrained\n","        model.train(False)\n","        for params in model.parameters():\n","            params.requires_grad = False\n","        #\n","        for params in model.resNet.layer4[0].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[0].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[1].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[1].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        for params in model.resNet.layer4[2].conv1.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","        #\n","        for params in model.resNet.layer4[2].conv2.parameters():\n","            params.requires_grad = True\n","            train_params += [params]\n","        #\n","        for params in model.resNet.fc.parameters():  # fully connected layer\n","            params.requires_grad = True\n","            train_params += [params]\n","\n","        model.resNet.layer4[0].conv1.train(True)\n","        model.resNet.layer4[0].conv2.train(True)\n","        model.resNet.layer4[1].conv1.train(True)\n","        model.resNet.layer4[1].conv2.train(True)\n","        model.resNet.layer4[2].conv1.train(True)\n","        model.resNet.layer4[2].conv2.train(True)\n","        model.resNet.fc.train(True)\n","\n","        if stage == 2:\n","          # set to train the self supervised\n","          for params in model.ms_task.parameters():\n","              params.requires_grad = True\n","              train_params += [params]\n","\n","        if stage == 3:\n","          # motion condition layer\n","          for params in model.resNet.condNet.parameters():\n","              params.requires_grad = True\n","              train_params += [params]\n","\n","          # motion modulation layer\n","          for params in model.resNet.sft.parameters():\n","              params.requires_grad = True\n","              train_params += [params]\n","\n","    for params in model.lstm_cell.parameters():  # for both stages we train the lstm\n","        params.requires_grad = True\n","        train_params += [params]\n","\n","    for params in model.classifier.parameters():  # for both stages we train the last classifier (after the lstm and avg pooling)\n","        params.requires_grad = True\n","        train_params += [params]\n","\n","    model.lstm_cell.train(True)\n","\n","    model.classifier.train(True)\n","    model.cuda()\n","\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n","\n","    optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                           gamma=decay_factor)\n","\n","    train_iter = 0\n","    min_accuracy = 0\n","\n","    for epoch in range(numEpochs):\n","        optim_scheduler.step()\n","        epoch_loss = 0\n","        epoch_ms_loss = 0\n","        numCorrTrain = 0\n","        trainSamples = 0\n","        iterPerEpoch = 0\n","        model.lstm_cell.train(True)\n","        model.classifier.train(True)\n","        if stage > 1:\n","          model.resNet.layer4[0].conv1.train(True)\n","          model.resNet.layer4[0].conv2.train(True)\n","          model.resNet.layer4[1].conv1.train(True)\n","          model.resNet.layer4[1].conv2.train(True)\n","          model.resNet.layer4[2].conv1.train(True)\n","          model.resNet.layer4[2].conv2.train(True)\n","          model.resNet.fc.train(True)\n","\n","          if stage == 2:\n","              model.ms_task.conv.train(True)\n","              model.ms_task.fc.train(True)\n","\n","          if stage == 3:\n","              # motion layers\n","              model.resNet.sft.train(True)\n","              model.resNet.condNet.train(True)\n","\n","\n","        start = time.time()\n","        for i, (inputFrame, inputMMaps, inputFlow, targets) in enumerate(train_loader):\n","            train_iter += 1\n","            iterPerEpoch += 1\n","            optimizer_fn.zero_grad()\n","            inputFrameVariable = Variable(\n","                inputFrame.permute(1, 0, 2, 3, 4).to(DEVICE))  # sequence length as first dimension\n","\n","            # flow data is reshaped to have x and y as channels\n","            inputFlow = inputFlow.view(\n","                (inputFlow.shape[0], int(inputFlow.shape[1] / 2), 2, inputFlow.shape[2], inputFlow.shape[3]))\n","            inputFlowVariable = Variable(\n","                inputFlow.permute(1, 0, 2, 3, 4).to(DEVICE))  # sequence length as first dimension\n","\n","            labelVariable = Variable(targets.to(DEVICE))\n","            trainSamples += inputFrame.size(0)\n","            output_label, _, ms_lab = model((inputFrameVariable, inputFlowVariable), stage)\n","\n","            loss = loss_fn(output_label, labelVariable)\n","\n","            if stage == 2:\n","                ms_loss = loss_ms_fn(F.softmax(ms_lab, dim=1), mmaps_preparation(inputMMaps, 0.5))\n","                epoch_ms_loss += ms_loss.data.item()  #\n","                (loss + ms_loss).backward()\n","            else:\n","                loss.backward()\n","\n","            optimizer_fn.step()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorrTrain += (predicted == targets.to(DEVICE)).sum()  # evaluating number of correct classifications\n","            epoch_loss += loss.data.item()\n","        print(f\"Elapsed {time.time() - start}\")\n","\n","        avg_loss = epoch_loss / iterPerEpoch\n","        if stage == 2:\n","            avg_ms_loss = epoch_ms_loss / iterPerEpoch  #\n","\n","        trainAccuracy = (numCorrTrain.data.item() / trainSamples)\n","\n","        train_log_loss.write('Training loss after {} epoch = {}\\n'.format(epoch + 1, avg_loss))  # log file\n","        train_log_acc.write('Training accuracy after {} epoch = {}\\n'.format(epoch + 1, trainAccuracy))  # log file\n","        print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch + 1, avg_loss, trainAccuracy))\n","        if stage == 2:\n","            train_log_loss.write('Training ms loss after {} epoch = {}\\n'.format(epoch + 1, avg_ms_loss))  # log file\n","            print(\"ms avg epoch loss: {}\".format(avg_ms_loss))\n","\n","        if (epoch + 1) % VAL_FREQUENCY == 0:\n","            model.train(False)\n","            val_loss_epoch = 0\n","            val_ms_loss_epoch = 0\n","            val_iter = 0\n","            val_samples = 0\n","            numCorr = 0\n","            for j, (inputFrame, inputMMaps, inputFlow, targets) in enumerate(val_loader):\n","                val_iter += 1\n","                val_samples += inputFrame.size(0)\n","                inputFrameVariable = Variable(inputFrame.permute(1, 0, 2, 3, 4).to(DEVICE))\n","\n","                # flow data is reshaped to have x and y as channels\n","                inputFlow = inputFlow.view(\n","                    (inputFlow.shape[0], int(inputFlow.shape[1] / 2), 2, inputFlow.shape[2], inputFlow.shape[3]))\n","                inputFlowVariable = Variable(\n","                    inputFlow.permute(1, 0, 2, 3, 4).to(DEVICE))  # sequence length as first dimension\n","\n","                labelVariable = Variable(targets.to(DEVICE))\n","                output_label, _, ms_lab = model((inputFrameVariable, inputFlowVariable), stage)\n","                val_loss = loss_fn(output_label, labelVariable)\n","                val_loss_epoch += val_loss.data.item()\n","\n","                if stage == 2:\n","                    ms_loss = loss_ms_fn(F.softmax(ms_lab, dim=1), mmaps_preparation(inputMMaps, 0.5))  #\n","                    val_ms_loss_epoch += ms_loss.data.item()  #\n","\n","                _, predicted = torch.max(output_label.data, 1)\n","                numCorr += (predicted == targets.to(DEVICE)).sum()  # evaluating number of correct classifications\n","            val_accuracy = (numCorr.data.item() / val_samples)\n","            avg_val_loss = val_loss_epoch / val_iter\n","            avg_ms_loss = val_ms_loss_epoch / val_iter  #\n","\n","            print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","            val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))  # log file\n","            val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))  # log file\n","\n","            if stage == 2:\n","                val_log_loss.write('Val ms loss after {} epoch = {}\\n'.format(epoch + 1, avg_ms_loss))  # log file\n","                print(\"Ms Epoch: {}\".format(avg_ms_loss))\n","\n","            if val_accuracy > min_accuracy:\n","                save_path_model = (\n","                        model_folder + '/model_rgb_state_dict.pth')  # every epoch, check if the val accuracy is improved, if so, save that model\n","                torch.save(model.state_dict(),\n","                           save_path_model)  # in that way, even if the model overfit, you will get always the best model\n","                min_accuracy = val_accuracy  # in this way you don't have to care too much about the number of epochs\n","\n","    train_log_loss.close()\n","    train_log_acc.close()\n","    val_log_acc.close()\n","    val_log_loss.close()\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vX_Am4pWn3aa","colab_type":"code","colab":{}},"source":["def main():\n","    version = \"rgb_16frames_two_in_one_no_ms\"\n","    trainDatasetDir = \"/content/\"\n","    outDir = \"./results\"\n","    #stage1Dict = \"./\" + outDir + \"/\" + version + \"_1/model_rgb_state_dict.pth\"  # args.stage1Dict\n","\n","    stage1Dict = \"/content/drive/My Drive/Lorenzo/ego-rnn-latest/200+150epochs_RGB_16frames/test_1/model_rgb_state_dict.pth\"\n","    #stage1Dict = \"/content/drive/My Drive/Lorenzo/ego-rnn-latest/rgb_7frames/rgb_7frames_1/model_rgb_state_dict.pth\"\n","\n","    stage2Dict = \"./\" + outDir + \"/\" + version + \"_2/model_rgb_state_dict.pth\" \n","\n","    # STAGE 1 PARAMETERS\n","    ST1_seqLen = 16  # 7\n","    ST1_trainBatchSize = 32  # 32\n","    ST1_valBatchSize = 32  # 32\n","    ST1_numEpochs = 200  # 200\n","    ST1_lr1 = 1e-3  # 1e-3\n","    ST1_stepSize = [25, 75, 150]  # [25, 75, 150]\n","    ST1_decayRate = 0.1  # 0.1\n","    ST1_memSize = 512  # 512\n","\n","    # STAGE 2 PARAMETERS\n","    ST2_seqLen = 16  # 7\n","    ST2_trainBatchSize = 32  # 32\n","    ST2_valBatchSize = 32  # 32\n","    ST2_numEpochs = 150  # 150\n","    ST2_lr1 = 1e-4  # 1e-4\n","    ST2_stepSize = [25, 75]  # [25, 75]\n","    ST2_decayRate = 0.1  # 0.1\n","    ST2_memSize = 512  # 512\n","\n","    # STAGE 3 PARAMETERS\n","    ST3_seqLen = 16  # 7\n","    ST3_trainBatchSize = 4  # 32\n","    ST3_valBatchSize = 4  # 32\n","    ST3_numEpochs = 150  # 150\n","    ST3_lr1 = 1e-4  # 1e-4\n","    ST3_stepSize = [25, 75]  # [25, 75]\n","    ST3_decayRate = 0.1  # 0.1\n","    ST3_memSize = 512  # 512\n","\n","    # STAGE 1\n","    '''\n","    \n","    main_run(version + \"_1\",\n","             stage=1,\n","             train_data_dir=trainDatasetDir,\n","             stage1_dict=stage1Dict,\n","             out_dir=outDir,\n","             seqLen=ST1_seqLen,\n","             trainBatchSize=ST1_trainBatchSize,\n","             valBatchSize=ST1_valBatchSize,\n","             numEpochs=ST1_numEpochs,\n","             lr1=ST1_lr1,\n","             decay_factor=ST1_decayRate,\n","             decay_step=ST1_stepSize,\n","             mem_size=ST1_memSize)\n","    '''\n","    '''\n","    # STAGE 2\n","    main_run(version + \"_2\",\n","             stage=2,\n","             train_data_dir=trainDatasetDir,\n","             stage1_dict=stage1Dict,\n","             out_dir=outDir,\n","             seqLen=ST2_seqLen,\n","             trainBatchSize=ST2_trainBatchSize,\n","             valBatchSize=ST2_valBatchSize,\n","             numEpochs=ST2_numEpochs,\n","             lr1=ST2_lr1,\n","             decay_factor=ST2_decayRate,\n","             decay_step=ST2_stepSize,\n","             mem_size=ST2_memSize)\n","    '''\n","\n","    # STAGE 3\n","    main_run(version + \"_3\",\n","             stage=3,\n","             train_data_dir=trainDatasetDir,\n","             stage1_dict=stage1Dict,  ######\n","             out_dir=outDir,\n","             seqLen=ST2_seqLen,\n","             trainBatchSize=ST3_trainBatchSize,\n","             valBatchSize=ST3_valBatchSize,\n","             numEpochs=ST3_numEpochs,\n","             lr1=ST3_lr1,\n","             decay_factor=ST3_decayRate,\n","             decay_step=ST3_stepSize,\n","             mem_size=ST3_memSize)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5eK4A48Rrm-r","colab_type":"code","outputId":"e7c8d6ea-5343-4efd-9828-9c0494383e5d","executionInfo":{"status":"ok","timestamp":1591102775513,"user_tz":-120,"elapsed":2412,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pwd"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Zk69KSzysC_-","colab_type":"code","colab":{}},"source":["#%rm \"-r\" \"/content/results/rgb_16frames_two_in_one\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUz2aKMpn6qa","colab_type":"code","outputId":"77e7a274-18b5-4ccc-b4e8-a1bf369452dc","executionInfo":{"status":"ok","timestamp":1591113193637,"user_tz":-120,"elapsed":3259010,"user":{"displayName":"Laboratorio MLDL","photoUrl":"","userId":"15250599834567100244"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["skipped /content/flow_x_processed/S1/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S1/take_honey/3, different frame number\n","skipped /content/flow_x_processed/S1/take_peanut/1, different frame number\n","skipped /content/flow_x_processed/S3/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/flow_x_processed/S3/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/flow_x_processed/S3/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/flow_x_processed/S3/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S3/pour_sugar,spoon,cup/4, different frame number\n","skipped /content/flow_x_processed/S3/stir_spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S4/pour_coffee,spoon,cup/1, different frame number\n","skipped /content/flow_x_processed/S4/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S4/pour_coffee,spoon,cup/3, different frame number\n","skipped /content/flow_x_processed/S4/pour_coffee,spoon,cup/4, different frame number\n","skipped /content/flow_x_processed/S4/pour_sugar,spoon,cup/1, different frame number\n","skipped /content/flow_x_processed/S4/pour_sugar,spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S4/pour_sugar,spoon,cup/3, different frame number\n","skipped /content/flow_x_processed/S2/pour_coffee,spoon,cup/2, different frame number\n","skipped /content/flow_x_processed/S2/take_mustard/1, different frame number\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:31: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_i_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:32: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_i_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:33: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_i_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:35: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_f_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:36: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_f_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:37: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_f_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:39: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_c_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:40: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_c_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:41: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_c_hh.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:43: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_o_xx.weight)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:44: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n","  torch.nn.init.constant(self.conv_o_xx.bias, 0)\n","/content/drive/My Drive/Lorenzo/ego-rnn-two-in-one/MyConvLSTMCell.py:45: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n","  torch.nn.init.xavier_normal(self.conv_o_hh.weight)\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Elapsed 66.20869517326355\n","Train: Epoch = 1 | Loss = 3.066507157756061 | Accuracy = 0.24307692307692308\n","Elapsed 66.62616276741028\n","Train: Epoch = 2 | Loss = 3.0205763251316258 | Accuracy = 0.2246153846153846\n","Elapsed 66.14443159103394\n","Train: Epoch = 3 | Loss = 2.8485332116848086 | Accuracy = 0.23076923076923078\n","Elapsed 66.26039862632751\n","Train: Epoch = 4 | Loss = 2.796463445919316 | Accuracy = 0.2553846153846154\n","Elapsed 66.01537871360779\n","Train: Epoch = 5 | Loss = 2.6468558006170317 | Accuracy = 0.27692307692307694\n","Val: Epoch = 5 | Loss 2.3155457932373573 | Accuracy = 0.3333333333333333\n","Elapsed 66.6812093257904\n","Train: Epoch = 6 | Loss = 2.5975013477046316 | Accuracy = 0.3446153846153846\n","Elapsed 65.8861768245697\n","Train: Epoch = 7 | Loss = 2.537867092504734 | Accuracy = 0.27076923076923076\n","Elapsed 66.64487481117249\n","Train: Epoch = 8 | Loss = 2.5127094882290537 | Accuracy = 0.31384615384615383\n","Elapsed 68.78859686851501\n","Train: Epoch = 9 | Loss = 2.55795983570378 | Accuracy = 0.3046153846153846\n","Elapsed 67.28980731964111\n","Train: Epoch = 10 | Loss = 2.4024749398231506 | Accuracy = 0.3261538461538461\n","Val: Epoch = 10 | Loss 2.1464571644519936 | Accuracy = 0.3684210526315789\n","Elapsed 68.45087122917175\n","Train: Epoch = 11 | Loss = 2.437923194431677 | Accuracy = 0.3323076923076923\n","Elapsed 67.82891798019409\n","Train: Epoch = 12 | Loss = 2.426181362896431 | Accuracy = 0.3353846153846154\n","Elapsed 71.2303535938263\n","Train: Epoch = 13 | Loss = 2.272170705039327 | Accuracy = 0.39384615384615385\n","Elapsed 75.38744616508484\n","Train: Epoch = 14 | Loss = 2.3494900174257234 | Accuracy = 0.3446153846153846\n","Elapsed 75.98307037353516\n","Train: Epoch = 15 | Loss = 2.2398108273017696 | Accuracy = 0.40615384615384614\n","Val: Epoch = 15 | Loss 2.2866021353622963 | Accuracy = 0.42105263157894735\n","Elapsed 68.0204930305481\n","Train: Epoch = 16 | Loss = 2.206322978182537 | Accuracy = 0.39076923076923076\n","Elapsed 67.37789630889893\n","Train: Epoch = 17 | Loss = 2.2289154587722404 | Accuracy = 0.35384615384615387\n","Elapsed 66.36698389053345\n","Train: Epoch = 18 | Loss = 2.263011491153298 | Accuracy = 0.36923076923076925\n","Elapsed 65.74627304077148\n","Train: Epoch = 19 | Loss = 2.3004878105186837 | Accuracy = 0.3230769230769231\n","Elapsed 65.80537557601929\n","Train: Epoch = 20 | Loss = 2.0850359368615035 | Accuracy = 0.4246153846153846\n","Val: Epoch = 20 | Loss 1.748977878998066 | Accuracy = 0.4649122807017544\n","Elapsed 66.36183595657349\n","Train: Epoch = 21 | Loss = 2.07439584921046 | Accuracy = 0.4123076923076923\n","Elapsed 65.9586238861084\n","Train: Epoch = 22 | Loss = 2.1003626417822954 | Accuracy = 0.4276923076923077\n","Elapsed 66.09133386611938\n","Train: Epoch = 23 | Loss = 2.096550313437857 | Accuracy = 0.39692307692307693\n","Elapsed 66.35382127761841\n","Train: Epoch = 24 | Loss = 1.906616688501544 | Accuracy = 0.48\n","Elapsed 65.92730569839478\n","Train: Epoch = 25 | Loss = 1.7128733178464377 | Accuracy = 0.47692307692307695\n","Val: Epoch = 25 | Loss 1.6905657977893436 | Accuracy = 0.5087719298245614\n","Elapsed 66.59083151817322\n","Train: Epoch = 26 | Loss = 1.7857070979548664 | Accuracy = 0.5169230769230769\n","Elapsed 66.2719304561615\n","Train: Epoch = 27 | Loss = 1.7646069453983773 | Accuracy = 0.49230769230769234\n","Elapsed 65.54522895812988\n","Train: Epoch = 28 | Loss = 1.6260615078414358 | Accuracy = 0.5353846153846153\n","Elapsed 66.18916273117065\n","Train: Epoch = 29 | Loss = 1.631277042918089 | Accuracy = 0.5169230769230769\n","Elapsed 65.90380644798279\n","Train: Epoch = 30 | Loss = 1.7735378945746072 | Accuracy = 0.5138461538461538\n","Val: Epoch = 30 | Loss 1.51699167901072 | Accuracy = 0.5263157894736842\n","Elapsed 66.04859590530396\n","Train: Epoch = 31 | Loss = 1.7898725918153437 | Accuracy = 0.4646153846153846\n","Elapsed 65.90946173667908\n","Train: Epoch = 32 | Loss = 1.5574671444369526 | Accuracy = 0.5230769230769231\n","Elapsed 66.03572154045105\n","Train: Epoch = 33 | Loss = 1.5885208852407409 | Accuracy = 0.5415384615384615\n","Elapsed 65.7434356212616\n","Train: Epoch = 34 | Loss = 1.4727105767261692 | Accuracy = 0.5538461538461539\n","Elapsed 65.77784848213196\n","Train: Epoch = 35 | Loss = 1.5523662879699613 | Accuracy = 0.5476923076923077\n","Val: Epoch = 35 | Loss 1.4434871283070794 | Accuracy = 0.5701754385964912\n","Elapsed 65.71154260635376\n","Train: Epoch = 36 | Loss = 1.5415607196528738 | Accuracy = 0.5507692307692308\n","Elapsed 66.01894187927246\n","Train: Epoch = 37 | Loss = 1.615699488942216 | Accuracy = 0.5138461538461538\n","Elapsed 65.82423806190491\n","Train: Epoch = 38 | Loss = 1.5454689082576007 | Accuracy = 0.5753846153846154\n","Elapsed 66.07941794395447\n","Train: Epoch = 39 | Loss = 1.510246892527836 | Accuracy = 0.56\n","Elapsed 67.54007649421692\n","Train: Epoch = 40 | Loss = 1.4256986045255893 | Accuracy = 0.5692307692307692\n","Val: Epoch = 40 | Loss 1.5851345021149208 | Accuracy = 0.5350877192982456\n","Elapsed 66.40430498123169\n","Train: Epoch = 41 | Loss = 1.49109815751634 | Accuracy = 0.6\n","Elapsed 66.7276120185852\n","Train: Epoch = 42 | Loss = 1.3868512431295907 | Accuracy = 0.6030769230769231\n","Elapsed 66.24230599403381\n","Train: Epoch = 43 | Loss = 1.3910716037924697 | Accuracy = 0.556923076923077\n","Elapsed 66.78698420524597\n","Train: Epoch = 44 | Loss = 1.4102474334763317 | Accuracy = 0.5784615384615385\n","Elapsed 66.48183226585388\n","Train: Epoch = 45 | Loss = 1.3591285427895987 | Accuracy = 0.6092307692307692\n","Val: Epoch = 45 | Loss 1.2486072573168525 | Accuracy = 0.6491228070175439\n","Elapsed 67.2399435043335\n","Train: Epoch = 46 | Loss = 1.414727113595823 | Accuracy = 0.5476923076923077\n","Elapsed 66.7575364112854\n","Train: Epoch = 47 | Loss = 1.516554849903758 | Accuracy = 0.5353846153846153\n","Elapsed 66.81402039527893\n","Train: Epoch = 48 | Loss = 1.3241089335302028 | Accuracy = 0.6061538461538462\n","Elapsed 65.77716088294983\n","Train: Epoch = 49 | Loss = 1.4718563709317185 | Accuracy = 0.5661538461538461\n","Elapsed 65.63868427276611\n","Train: Epoch = 50 | Loss = 1.420080131146966 | Accuracy = 0.5938461538461538\n","Val: Epoch = 50 | Loss 1.3568699236573845 | Accuracy = 0.631578947368421\n","Elapsed 65.32676887512207\n","Train: Epoch = 51 | Loss = 1.4122557363859036 | Accuracy = 0.5784615384615385\n","Elapsed 65.74015617370605\n","Train: Epoch = 52 | Loss = 1.4159123119784565 | Accuracy = 0.56\n","Elapsed 65.65702652931213\n","Train: Epoch = 53 | Loss = 1.344655122698807 | Accuracy = 0.5938461538461538\n","Elapsed 65.61519384384155\n","Train: Epoch = 54 | Loss = 1.4465184088160352 | Accuracy = 0.6123076923076923\n","Elapsed 65.29445147514343\n","Train: Epoch = 55 | Loss = 1.289570870195947 | Accuracy = 0.6061538461538462\n","Val: Epoch = 55 | Loss 1.3604583658021072 | Accuracy = 0.631578947368421\n","Elapsed 65.32878088951111\n","Train: Epoch = 56 | Loss = 1.2183185263377865 | Accuracy = 0.6492307692307693\n","Elapsed 64.99197006225586\n","Train: Epoch = 57 | Loss = 1.2583921224605747 | Accuracy = 0.6246153846153846\n","Elapsed 65.07116866111755\n","Train: Epoch = 58 | Loss = 1.2297291159629822 | Accuracy = 0.6246153846153846\n","Elapsed 64.73522806167603\n","Train: Epoch = 59 | Loss = 1.4734487221008394 | Accuracy = 0.556923076923077\n","Elapsed 64.86234188079834\n","Train: Epoch = 60 | Loss = 1.3455072379693753 | Accuracy = 0.6123076923076923\n","Val: Epoch = 60 | Loss 1.3384290871949032 | Accuracy = 0.5964912280701754\n","Elapsed 64.95932149887085\n","Train: Epoch = 61 | Loss = 1.224410025084891 | Accuracy = 0.6246153846153846\n","Elapsed 65.10596227645874\n","Train: Epoch = 62 | Loss = 1.2987094332532185 | Accuracy = 0.6184615384615385\n","Elapsed 64.98083662986755\n","Train: Epoch = 63 | Loss = 1.2785821557044983 | Accuracy = 0.6\n","Elapsed 65.0242052078247\n","Train: Epoch = 64 | Loss = 1.2490707257898843 | Accuracy = 0.6092307692307692\n","Elapsed 65.67970490455627\n","Train: Epoch = 65 | Loss = 1.1844369441997715 | Accuracy = 0.6492307692307693\n","Val: Epoch = 65 | Loss 1.3601641202795094 | Accuracy = 0.6228070175438597\n","Elapsed 65.2745099067688\n","Train: Epoch = 66 | Loss = 1.2936989585073984 | Accuracy = 0.6123076923076923\n","Elapsed 65.41371035575867\n","Train: Epoch = 67 | Loss = 1.1612128426388997 | Accuracy = 0.64\n","Elapsed 65.35010933876038\n","Train: Epoch = 68 | Loss = 1.2485450847846706 | Accuracy = 0.6369230769230769\n","Elapsed 65.44717907905579\n","Train: Epoch = 69 | Loss = 1.1592054279839121 | Accuracy = 0.6461538461538462\n","Elapsed 65.65729451179504\n","Train: Epoch = 70 | Loss = 1.2441149150452964 | Accuracy = 0.6123076923076923\n","Val: Epoch = 70 | Loss 1.3918000829630885 | Accuracy = 0.5964912280701754\n","Elapsed 66.52613663673401\n","Train: Epoch = 71 | Loss = 1.242315783006389 | Accuracy = 0.5907692307692308\n","Elapsed 67.97719311714172\n","Train: Epoch = 72 | Loss = 1.2059591710567474 | Accuracy = 0.6338461538461538\n","Elapsed 66.04095077514648\n","Train: Epoch = 73 | Loss = 1.199993257115527 | Accuracy = 0.6153846153846154\n","Elapsed 66.17997074127197\n","Train: Epoch = 74 | Loss = 1.2301617962558096 | Accuracy = 0.6584615384615384\n","Elapsed 65.76827144622803\n","Train: Epoch = 75 | Loss = 0.9939780700497511 | Accuracy = 0.676923076923077\n","Val: Epoch = 75 | Loss 1.2502126590958957 | Accuracy = 0.6491228070175439\n","Elapsed 65.4082715511322\n","Train: Epoch = 76 | Loss = 1.2100892495818254 | Accuracy = 0.6276923076923077\n","Elapsed 65.67810606956482\n","Train: Epoch = 77 | Loss = 1.1832847900506926 | Accuracy = 0.64\n","Elapsed 65.9524176120758\n","Train: Epoch = 78 | Loss = 1.1652235337873784 | Accuracy = 0.6584615384615384\n","Elapsed 65.8818736076355\n","Train: Epoch = 79 | Loss = 1.2919530047149193 | Accuracy = 0.6246153846153846\n","Elapsed 65.8954005241394\n","Train: Epoch = 80 | Loss = 1.1942410578088063 | Accuracy = 0.64\n","Val: Epoch = 80 | Loss 1.28502108310831 | Accuracy = 0.6052631578947368\n","Elapsed 66.05990505218506\n","Train: Epoch = 81 | Loss = 1.115228567181564 | Accuracy = 0.6676923076923077\n","Elapsed 65.56407308578491\n","Train: Epoch = 82 | Loss = 1.155716218599459 | Accuracy = 0.6676923076923077\n","Elapsed 65.47831082344055\n","Train: Epoch = 83 | Loss = 1.0831016222151315 | Accuracy = 0.6676923076923077\n","Elapsed 65.8262026309967\n","Train: Epoch = 84 | Loss = 1.230134937094479 | Accuracy = 0.6246153846153846\n","Elapsed 65.39564609527588\n","Train: Epoch = 85 | Loss = 1.179982668016015 | Accuracy = 0.6492307692307693\n","Val: Epoch = 85 | Loss 1.232229101246801 | Accuracy = 0.6228070175438597\n","Elapsed 65.77176928520203\n","Train: Epoch = 86 | Loss = 1.172303846696528 | Accuracy = 0.6184615384615385\n","Elapsed 65.49920463562012\n","Train: Epoch = 87 | Loss = 1.095348026694321 | Accuracy = 0.6461538461538462\n","Elapsed 65.84778499603271\n","Train: Epoch = 88 | Loss = 1.2202437970696427 | Accuracy = 0.6338461538461538\n","Elapsed 66.00356602668762\n","Train: Epoch = 89 | Loss = 1.2356429078230045 | Accuracy = 0.6369230769230769\n","Elapsed 65.70693278312683\n","Train: Epoch = 90 | Loss = 1.0630982627228993 | Accuracy = 0.676923076923077\n","Val: Epoch = 90 | Loss 1.1796500600617508 | Accuracy = 0.6666666666666666\n","Elapsed 66.1426522731781\n","Train: Epoch = 91 | Loss = 1.1793485530992833 | Accuracy = 0.6553846153846153\n","Elapsed 65.67693328857422\n","Train: Epoch = 92 | Loss = 1.119793854108671 | Accuracy = 0.6276923076923077\n","Elapsed 65.09832525253296\n","Train: Epoch = 93 | Loss = 1.2144450894216212 | Accuracy = 0.6276923076923077\n","Elapsed 65.05681562423706\n","Train: Epoch = 94 | Loss = 1.1790964639768369 | Accuracy = 0.64\n","Elapsed 65.28690814971924\n","Train: Epoch = 95 | Loss = 1.1562757462989994 | Accuracy = 0.6646153846153846\n","Val: Epoch = 95 | Loss 1.4059810001274635 | Accuracy = 0.5964912280701754\n","Elapsed 64.87198305130005\n","Train: Epoch = 96 | Loss = 1.0711167760011626 | Accuracy = 0.6707692307692308\n","Elapsed 65.29119372367859\n","Train: Epoch = 97 | Loss = 1.0813746772161343 | Accuracy = 0.6646153846153846\n","Elapsed 66.08319401741028\n","Train: Epoch = 98 | Loss = 1.097070681612666 | Accuracy = 0.6707692307692308\n","Elapsed 65.89896512031555\n","Train: Epoch = 99 | Loss = 1.0177780600582682 | Accuracy = 0.6892307692307692\n","Elapsed 65.98045563697815\n","Train: Epoch = 100 | Loss = 1.1727406033655492 | Accuracy = 0.6676923076923077\n","Val: Epoch = 100 | Loss 1.2622656390584748 | Accuracy = 0.6491228070175439\n","Elapsed 65.54647445678711\n","Train: Epoch = 101 | Loss = 1.194397559980067 | Accuracy = 0.6184615384615385\n","Elapsed 65.69090938568115\n","Train: Epoch = 102 | Loss = 1.111470805435646 | Accuracy = 0.6246153846153846\n","Elapsed 65.54548478126526\n","Train: Epoch = 103 | Loss = 1.1633492715475036 | Accuracy = 0.6584615384615384\n","Elapsed 64.92742013931274\n","Train: Epoch = 104 | Loss = 1.2472407003728354 | Accuracy = 0.6307692307692307\n","Elapsed 65.53910112380981\n","Train: Epoch = 105 | Loss = 1.1023380276633472 | Accuracy = 0.6461538461538462\n","Val: Epoch = 105 | Loss 1.2828673206526657 | Accuracy = 0.6228070175438597\n","Elapsed 64.95608496665955\n","Train: Epoch = 106 | Loss = 1.2821877715064258 | Accuracy = 0.6153846153846154\n","Elapsed 65.34786295890808\n","Train: Epoch = 107 | Loss = 1.1272283966948347 | Accuracy = 0.6676923076923077\n","Elapsed 65.66927194595337\n","Train: Epoch = 108 | Loss = 1.0861228849829696 | Accuracy = 0.6615384615384615\n","Elapsed 65.71815323829651\n","Train: Epoch = 109 | Loss = 1.107958708594485 | Accuracy = 0.6523076923076923\n","Elapsed 65.70351529121399\n","Train: Epoch = 110 | Loss = 1.0667597680557064 | Accuracy = 0.6953846153846154\n","Val: Epoch = 110 | Loss 1.2987382576383393 | Accuracy = 0.5964912280701754\n","Elapsed 65.78113055229187\n","Train: Epoch = 111 | Loss = 1.2041384025317867 | Accuracy = 0.6276923076923077\n","Elapsed 65.33842754364014\n","Train: Epoch = 112 | Loss = 1.080310995258936 | Accuracy = 0.68\n","Elapsed 65.40107297897339\n","Train: Epoch = 113 | Loss = 1.112463538239642 | Accuracy = 0.683076923076923\n","Elapsed 65.26658654212952\n","Train: Epoch = 114 | Loss = 1.1431862886359052 | Accuracy = 0.6492307692307693\n","Elapsed 65.33018159866333\n","Train: Epoch = 115 | Loss = 1.012853363665139 | Accuracy = 0.6892307692307692\n","Val: Epoch = 115 | Loss 1.2622401899304883 | Accuracy = 0.5877192982456141\n","Elapsed 65.33748650550842\n","Train: Epoch = 116 | Loss = 1.011553596432616 | Accuracy = 0.7076923076923077\n","Elapsed 65.53638291358948\n","Train: Epoch = 117 | Loss = 1.0858366373108654 | Accuracy = 0.6646153846153846\n","Elapsed 65.47278070449829\n","Train: Epoch = 118 | Loss = 1.1232837445852233 | Accuracy = 0.6553846153846153\n","Elapsed 65.92489194869995\n","Train: Epoch = 119 | Loss = 1.015797693554948 | Accuracy = 0.683076923076923\n","Elapsed 65.60438752174377\n","Train: Epoch = 120 | Loss = 1.0843043479977585 | Accuracy = 0.6646153846153846\n","Val: Epoch = 120 | Loss 1.2893598819601124 | Accuracy = 0.6491228070175439\n","Elapsed 65.35803127288818\n","Train: Epoch = 121 | Loss = 1.1032870673551791 | Accuracy = 0.6676923076923077\n","Elapsed 65.21751809120178\n","Train: Epoch = 122 | Loss = 1.0846344210752628 | Accuracy = 0.68\n","Elapsed 65.69555068016052\n","Train: Epoch = 123 | Loss = 0.9721446378928859 | Accuracy = 0.6892307692307692\n","Elapsed 65.30369997024536\n","Train: Epoch = 124 | Loss = 1.1500965749345176 | Accuracy = 0.6615384615384615\n","Elapsed 65.11335802078247\n","Train: Epoch = 125 | Loss = 1.095050680928114 | Accuracy = 0.6676923076923077\n","Val: Epoch = 125 | Loss 1.2949695093878384 | Accuracy = 0.6403508771929824\n","Elapsed 65.17725706100464\n","Train: Epoch = 126 | Loss = 1.079783222297343 | Accuracy = 0.683076923076923\n","Elapsed 65.05779385566711\n","Train: Epoch = 127 | Loss = 1.1149374944407766 | Accuracy = 0.676923076923077\n","Elapsed 65.05880665779114\n","Train: Epoch = 128 | Loss = 1.1101792222116051 | Accuracy = 0.64\n","Elapsed 64.90024662017822\n","Train: Epoch = 129 | Loss = 1.1831004423339193 | Accuracy = 0.6338461538461538\n","Elapsed 65.58936643600464\n","Train: Epoch = 130 | Loss = 0.979086821399084 | Accuracy = 0.6953846153846154\n","Val: Epoch = 130 | Loss 1.3348765948723103 | Accuracy = 0.6403508771929824\n","Elapsed 65.3926408290863\n","Train: Epoch = 131 | Loss = 1.208332549508025 | Accuracy = 0.6461538461538462\n","Elapsed 65.44331121444702\n","Train: Epoch = 132 | Loss = 0.965858156361231 | Accuracy = 0.7230769230769231\n","Elapsed 65.52299380302429\n","Train: Epoch = 133 | Loss = 1.1970305769908718 | Accuracy = 0.64\n","Elapsed 65.7955367565155\n","Train: Epoch = 134 | Loss = 1.1663066504932031 | Accuracy = 0.6646153846153846\n","Elapsed 65.60084295272827\n","Train: Epoch = 135 | Loss = 1.184070860467306 | Accuracy = 0.6246153846153846\n","Val: Epoch = 135 | Loss 1.181336337122424 | Accuracy = 0.6666666666666666\n","Elapsed 65.70903992652893\n","Train: Epoch = 136 | Loss = 1.0568549444035786 | Accuracy = 0.6953846153846154\n","Elapsed 65.38941168785095\n","Train: Epoch = 137 | Loss = 1.1297827719188318 | Accuracy = 0.6615384615384615\n","Elapsed 65.57342267036438\n","Train: Epoch = 138 | Loss = 0.9608619227641966 | Accuracy = 0.6984615384615385\n","Elapsed 66.9587128162384\n","Train: Epoch = 139 | Loss = 1.0559039188594352 | Accuracy = 0.6892307692307692\n","Elapsed 66.02054166793823\n","Train: Epoch = 140 | Loss = 1.2030251585855716 | Accuracy = 0.6184615384615385\n","Val: Epoch = 140 | Loss 1.2596863384904533 | Accuracy = 0.6228070175438597\n","Elapsed 66.26162838935852\n","Train: Epoch = 141 | Loss = 1.1265320276341788 | Accuracy = 0.64\n","Elapsed 66.51886439323425\n","Train: Epoch = 142 | Loss = 1.0491580737800132 | Accuracy = 0.6676923076923077\n","Elapsed 66.49750995635986\n","Train: Epoch = 143 | Loss = 1.0648464647735036 | Accuracy = 0.6676923076923077\n","Elapsed 66.06829595565796\n","Train: Epoch = 144 | Loss = 1.1080728645731763 | Accuracy = 0.6738461538461539\n","Elapsed 66.21357655525208\n","Train: Epoch = 145 | Loss = 1.0883917881221306 | Accuracy = 0.6707692307692308\n","Val: Epoch = 145 | Loss 1.1281413045422783 | Accuracy = 0.6754385964912281\n","Elapsed 66.22384572029114\n","Train: Epoch = 146 | Loss = 1.0001976773506258 | Accuracy = 0.7046153846153846\n","Elapsed 66.2428731918335\n","Train: Epoch = 147 | Loss = 1.0700697942477901 | Accuracy = 0.7046153846153846\n","Elapsed 66.14861917495728\n","Train: Epoch = 148 | Loss = 1.0539321637735135 | Accuracy = 0.6892307692307692\n","Elapsed 66.56100058555603\n","Train: Epoch = 149 | Loss = 1.0242909338416122 | Accuracy = 0.7015384615384616\n","Elapsed 66.56449913978577\n","Train: Epoch = 150 | Loss = 1.0941116693543225 | Accuracy = 0.6523076923076923\n","Val: Epoch = 150 | Loss 1.2926416027134862 | Accuracy = 0.6491228070175439\n"],"name":"stdout"}]}]}